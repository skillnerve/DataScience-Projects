{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Seq2SeqImplementation__Assignment.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwPL0hIlGKoA"
      },
      "source": [
        "# <font color='red'>**Sequence to sequence implementation**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-nYHE_1ck2az"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_check_encoder(), grader_check_attention(), grader_onestepdecoder() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**\n",
        "\n",
        "**Note 1:**  There are many blogs on the attention mechanisum which might be misleading you,\n",
        " so do read the references completly and after that only please check the internet.\n",
        " The best things is to read the research papers and try to implement it on your own. \n",
        "\n",
        "**Note 2:** To complete this assignment, the reference that are mentioned will be enough.\n",
        "\n",
        "**Note 3:** If you are starting this assignment, you might have completed minimum of 20 assignment.\n",
        " If  you are still not able to implement this algorithm you might have rushed in the previous assignments \n",
        "with out learning much and didn't spend your time productively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyfZo8fmLOec"
      },
      "source": [
        "## Task -1: Simple Encoder and Decoder\n",
        "Implement simple Encoder-Decoder model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IvNSZXNkkOkO"
      },
      "source": [
        "1. Download the **Italian** to **English** translation dataset from <a href=\"http://www.manythings.org/anki/ita-eng.zip\">here</a>\n",
        "\n",
        "2. You will find **ita.txt** file in that ZIP, \n",
        "you can read that data using python and preprocess that data this way only: \n",
        "<img src='https://i.imgur.com/z0j79Jf.png'>    \n",
        "    \n",
        "3. You have to implement a simple Encoder and Decoder architecture  \n",
        "\n",
        "4. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "5. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "6.  a. Check the reference notebook <br>\n",
        "    b. <a href=\"https://medium.com/analytics-vidhya/understand-sequence-to-sequence-models-in-a-more-intuitive-way-1d517d8795bb\">Resource 2</a>\n",
        "    \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChweBAlWQPei"
      },
      "source": [
        "<font color='blue'>**Libraries**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NEeWSztkQPej"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Input, Softmax, RNN\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import re\n",
        "import nltk\n",
        "from datetime import datetime \n",
        "tf.config.run_functions_eagerly(True)"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yqHe6QaSQvk9",
        "outputId": "1a1fa1d1-bf85-4d3c-882e-2ddf510461ca"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R9Ne1-Vx7got"
      },
      "source": [
        "%load_ext tensorboard"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k_AlAuKJqVA"
      },
      "source": [
        "<font color='blue'>**Load the data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fU80Ao-AGaob",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 212
        },
        "outputId": "00d9d98a-4c3c-4c27-c2c5-5daadc5ab87c"
      },
      "source": [
        "with open('/content/drive/MyDrive/ita.txt', 'r', encoding=\"utf8\") as f:\n",
        "    eng=[]\n",
        "    ita=[]\n",
        "    for i in f.readlines():\n",
        "        eng.append(i.split(\"\\t\")[0])\n",
        "        ita.append(i.split(\"\\t\")[1])\n",
        "data = pd.DataFrame(data=list(zip(eng, ita)), columns=['english','italian'])\n",
        "print(data.shape)\n",
        "data.head()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(343813, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Hi.</td>\n",
              "      <td>Ciao!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corri!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Corra!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Run!</td>\n",
              "      <td>Correte!</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Who?</td>\n",
              "      <td>Chi?</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english   italian\n",
              "0     Hi.     Ciao!\n",
              "1    Run!    Corri!\n",
              "2    Run!    Corra!\n",
              "3    Run!  Correte!\n",
              "4    Who?      Chi?"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmGWTdRmKRph"
      },
      "source": [
        "<font color='blue'>**Preprocess data**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QqElB_nKZos",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "43ebf194-5db4-43b7-9de1-49aeaaf0e77b"
      },
      "source": [
        "def decontractions(phrase):\n",
        "    \"\"\"decontracted takes text and convert contractions into natural form.\n",
        "     ref: https://stackoverflow.com/questions/19790188/expanding-english-language-contractions-in-python/47091490#47091490\"\"\"\n",
        "    # specific\n",
        "    phrase = re.sub(r\"won\\'t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\'t\", \"can not\", phrase)\n",
        "    phrase = re.sub(r\"won\\’t\", \"will not\", phrase)\n",
        "    phrase = re.sub(r\"can\\’t\", \"can not\", phrase)\n",
        "\n",
        "    # general\n",
        "    phrase = re.sub(r\"n\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\'s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\'d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\'ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\'t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\'ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\'m\", \" am\", phrase)\n",
        "\n",
        "    phrase = re.sub(r\"n\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’re\", \" are\", phrase)\n",
        "    phrase = re.sub(r\"\\’s\", \" is\", phrase)\n",
        "    phrase = re.sub(r\"\\’d\", \" would\", phrase)\n",
        "    phrase = re.sub(r\"\\’ll\", \" will\", phrase)\n",
        "    phrase = re.sub(r\"\\’t\", \" not\", phrase)\n",
        "    phrase = re.sub(r\"\\’ve\", \" have\", phrase)\n",
        "    phrase = re.sub(r\"\\’m\", \" am\", phrase)\n",
        "\n",
        "    return phrase\n",
        "\n",
        "def preprocess(text):\n",
        "    # convert all the text into lower letters\n",
        "    # use this function to remove the contractions: https://gist.github.com/anandborad/d410a49a493b56dace4f814ab5325bbd\n",
        "    # remove all the spacial characters: except space ' '\n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[^A-Za-z0-9 ]+', '', text)\n",
        "    return text\n",
        "\n",
        "def preprocess_ita(text):\n",
        "    # convert all the text into lower letters\n",
        "    # remove the words betweent brakets ()\n",
        "    # remove these characters: {'$', ')', '?', '\"', '’', '.',  '°', '!', ';', '/', \"'\", '€', '%', ':', ',', '('}\n",
        "    # replace these spl characters with space: '\\u200b', '\\xa0', '-', '/'\n",
        "    # we have found these characters after observing the data points, feel free to explore more and see if you can do find more\n",
        "    # you are free to do more proprocessing\n",
        "    # note that the model will learn better with better preprocessed data \n",
        "    \n",
        "    text = text.lower()\n",
        "    text = decontractions(text)\n",
        "    text = re.sub('[$)\\?\"’.°!;\\'€%:,(/]', '', text)\n",
        "    text = re.sub('\\u200b', ' ', text)\n",
        "    text = re.sub('\\xa0', ' ', text)\n",
        "    text = re.sub('-', ' ', text)\n",
        "    return text\n",
        "\n",
        "\n",
        "data['english'] = data['english'].apply(preprocess)\n",
        "data['italian'] = data['italian'].apply(preprocess_ita)\n",
        "data.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>hi</td>\n",
              "      <td>ciao</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>run</td>\n",
              "      <td>corri</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>run</td>\n",
              "      <td>corra</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>run</td>\n",
              "      <td>correte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>who</td>\n",
              "      <td>chi</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  english  italian\n",
              "0      hi     ciao\n",
              "1     run    corri\n",
              "2     run    corra\n",
              "3     run  correte\n",
              "4     who      chi"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JxNGCGf9QPem",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "77a650d6-a4af-4f5b-849a-196a4625f158"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>english</th>\n",
              "      <th>italian</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2773</th>\n",
              "      <td>i disagree</td>\n",
              "      <td>non sono daccordo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343499</th>\n",
              "      <td>if you do not want to put on sunscreen that is...</td>\n",
              "      <td>se non vi volete mettere della protezione sola...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73788</th>\n",
              "      <td>i never told anyone</td>\n",
              "      <td>io non lho mai detto a qualcuno</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153482</th>\n",
              "      <td>they want to become rich</td>\n",
              "      <td>vogliono diventare ricche</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324412</th>\n",
              "      <td>i bought a watch and i lost it the next day</td>\n",
              "      <td>comprai un orologio e lo persi il giorno succe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284748</th>\n",
              "      <td>what is important is the experience</td>\n",
              "      <td>quello che è importante è lesperienza</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3317</th>\n",
              "      <td>is it free</td>\n",
              "      <td>è gratuita</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31026</th>\n",
              "      <td>we both laughed</td>\n",
              "      <td>abbiamo entrambe riso</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332167</th>\n",
              "      <td>grandmother is ashes are in an urn at the temple</td>\n",
              "      <td>le ceneri della nonna sono in unurna nel tempio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227144</th>\n",
              "      <td>please give me your attention</td>\n",
              "      <td>per piacere mi dia la sua attenzione</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  english                                            italian\n",
              "2773                                           i disagree                                  non sono daccordo\n",
              "343499  if you do not want to put on sunscreen that is...  se non vi volete mettere della protezione sola...\n",
              "73788                                 i never told anyone                    io non lho mai detto a qualcuno\n",
              "153482                           they want to become rich                          vogliono diventare ricche\n",
              "324412        i bought a watch and i lost it the next day  comprai un orologio e lo persi il giorno succe...\n",
              "284748                what is important is the experience              quello che è importante è lesperienza\n",
              "3317                                           is it free                                         è gratuita\n",
              "31026                                     we both laughed                              abbiamo entrambe riso\n",
              "332167   grandmother is ashes are in an urn at the temple    le ceneri della nonna sono in unurna nel tempio\n",
              "227144                      please give me your attention               per piacere mi dia la sua attenzione"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vaakZsSQPen"
      },
      "source": [
        "ita_lengths = data['italian'].str.split().apply(len)\n",
        "eng_lengths = data['english'].str.split().apply(len)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6IeT4pN4QPen",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fa79266-3600-4e85-8a91-6312fa66320d"
      },
      "source": [
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(ita_lengths, i))\n",
        "for i in [99.1,99.2,99.3,99.4,99.5,99.6,99.7,99.8,99.9,100]:\n",
        "    print(i,np.percentile(eng_lengths, i))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99.1 12.0\n",
            "99.2 12.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 13.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 20.0\n",
            "100 92.0\n",
            "99.1 12.0\n",
            "99.2 13.0\n",
            "99.3 13.0\n",
            "99.4 13.0\n",
            "99.5 14.0\n",
            "99.6 14.0\n",
            "99.7 15.0\n",
            "99.8 16.0\n",
            "99.9 21.18800000002375\n",
            "100 101.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPTeA6xrQPen",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "a0d3d8ea-a40d-4cb1-e450-572ce55a333f"
      },
      "source": [
        "data['italian_len'] = data['italian'].str.split().apply(len)\n",
        "data = data[data['italian_len'] < 20]\n",
        "\n",
        "data['english_len'] = data['english'].str.split().apply(len)\n",
        "data = data[data['english_len'] < 20]\n",
        "\n",
        "data['english_inp'] = '<start> ' + data['english'].astype(str)\n",
        "data['english_out'] = data['english'].astype(str) + ' <end>'\n",
        "\n",
        "data = data.drop(['english','italian_len','english_len'], axis=1)\n",
        "# only for the first sentance add a toke <end> so that we will have <end> in tokenizer\n",
        "data.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ciao</td>\n",
              "      <td>&lt;start&gt; hi</td>\n",
              "      <td>hi &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>corri</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>corra</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>correte</td>\n",
              "      <td>&lt;start&gt; run</td>\n",
              "      <td>run &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>chi</td>\n",
              "      <td>&lt;start&gt; who</td>\n",
              "      <td>who &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   italian  english_inp english_out\n",
              "0     ciao   <start> hi    hi <end>\n",
              "1    corri  <start> run   run <end>\n",
              "2    corra  <start> run   run <end>\n",
              "3  correte  <start> run   run <end>\n",
              "4      chi  <start> who   who <end>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frmPcFR1QPeo",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "outputId": "7e44d05c-63eb-43fc-f4ef-b1adde0541bf"
      },
      "source": [
        "data.sample(10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>italian</th>\n",
              "      <th>english_inp</th>\n",
              "      <th>english_out</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>236174</th>\n",
              "      <td>io vado alle hawaii lanno prossimo</td>\n",
              "      <td>&lt;start&gt; i am going to hawaii next year</td>\n",
              "      <td>i am going to hawaii next year &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72151</th>\n",
              "      <td>anche io sono un maestro</td>\n",
              "      <td>&lt;start&gt; i am a teacher too</td>\n",
              "      <td>i am a teacher too &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237405</th>\n",
              "      <td>lo sapevo che oggi sarebbe divertente</td>\n",
              "      <td>&lt;start&gt; i knew that today would be fun</td>\n",
              "      <td>i knew that today would be fun &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320499</th>\n",
              "      <td>tom dice che non potrebbe mai vivere in australia</td>\n",
              "      <td>&lt;start&gt; tom says he could never live in australia</td>\n",
              "      <td>tom says he could never live in australia &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245054</th>\n",
              "      <td>perché sembrate così preoccupati</td>\n",
              "      <td>&lt;start&gt; why are you looking so worried</td>\n",
              "      <td>why are you looking so worried &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192811</th>\n",
              "      <td>ha messo la scatola sul tavolo</td>\n",
              "      <td>&lt;start&gt; he put the box on the table</td>\n",
              "      <td>he put the box on the table &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154538</th>\n",
              "      <td>tom spera che ti piaccia</td>\n",
              "      <td>&lt;start&gt; tom hopes you will like it</td>\n",
              "      <td>tom hopes you will like it &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126676</th>\n",
              "      <td>chi stai proteggendo</td>\n",
              "      <td>&lt;start&gt; who are you protecting</td>\n",
              "      <td>who are you protecting &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126498</th>\n",
              "      <td>dove sono le bambine</td>\n",
              "      <td>&lt;start&gt; where are the children</td>\n",
              "      <td>where are the children &lt;end&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312775</th>\n",
              "      <td>tom mi disturbò con molte domande</td>\n",
              "      <td>&lt;start&gt; tom bothered me with a lot of questions</td>\n",
              "      <td>tom bothered me with a lot of questions &lt;end&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  italian  ...                                      english_out\n",
              "236174                 io vado alle hawaii lanno prossimo  ...             i am going to hawaii next year <end>\n",
              "72151                            anche io sono un maestro  ...                         i am a teacher too <end>\n",
              "237405              lo sapevo che oggi sarebbe divertente  ...             i knew that today would be fun <end>\n",
              "320499  tom dice che non potrebbe mai vivere in australia  ...  tom says he could never live in australia <end>\n",
              "245054                   perché sembrate così preoccupati  ...             why are you looking so worried <end>\n",
              "192811                     ha messo la scatola sul tavolo  ...                he put the box on the table <end>\n",
              "154538                           tom spera che ti piaccia  ...                 tom hopes you will like it <end>\n",
              "126676                               chi stai proteggendo  ...                     who are you protecting <end>\n",
              "126498                               dove sono le bambine  ...                     where are the children <end>\n",
              "312775                  tom mi disturbò con molte domande  ...    tom bothered me with a lot of questions <end>\n",
              "\n",
              "[10 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4t9USgv4GB3"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "train, validation = train_test_split(data, test_size=0.2)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QeFmENnDSn3T",
        "outputId": "86624f3b-ff9f-4555-d1be-3ac83133d342"
      },
      "source": [
        "print(train.shape, validation.shape)\r\n",
        "train.iloc[0]['english_inp']= str(train.iloc[0]['english_inp'])+' <end>'\r\n",
        "train.iloc[0]['english_out']= str(train.iloc[0]['english_out'])+' <end>'"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(274710, 3) (68678, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkSuZs4e1Mvc"
      },
      "source": [
        "tknizer_ita = Tokenizer()\r\n",
        "tknizer_ita.fit_on_texts(train['italian'].values)\r\n",
        "tknizer_eng = Tokenizer(filters='!\"#$%&()*+,-./:;=?@[\\\\]^_`{|}~\\t\\n')\r\n",
        "tknizer_eng.fit_on_texts(train['english_inp'].values)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o8TVQQ19S4rs",
        "outputId": "ef24a10f-98bb-4068-fbe9-79bc92b094b5"
      },
      "source": [
        "tknizer_eng.word_index['<start>'], tknizer_eng.word_index['<end>']"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 10128)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "waPJv1-V1Q29",
        "outputId": "8ba140b3-8b37-4780-d97a-409c84e58d2e"
      },
      "source": [
        "vocab_size_eng=len(tknizer_eng.word_index.keys())\r\n",
        "print(vocab_size_eng)\r\n",
        "vocab_size_ita=len(tknizer_ita.word_index.keys())\r\n",
        "print(vocab_size_ita)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "12854\n",
            "26208\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVUl7Zqm0tch",
        "outputId": "1014177b-f294-45b4-fffc-8762c6167780"
      },
      "source": [
        "from tqdm import tqdm\r\n",
        "embeddings_index = dict()\r\n",
        "f = open('/content/drive/MyDrive/Data/glove.6B.100d.txt','rb')\r\n",
        "for line in tqdm(f):\r\n",
        "    values = line.split()\r\n",
        "    word = re.sub('b\\'','',str(values[0]))\r\n",
        "    word = word[:-1]\r\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\r\n",
        "    embeddings_index[word] = coefs\r\n",
        "f.close()\r\n",
        "\r\n",
        "embedding_matrix = np.zeros((vocab_size_eng+1, 100))\r\n",
        "for word, i in tknizer_eng.word_index.items():\r\n",
        "    embedding_vector = embeddings_index.get(word)\r\n",
        "    if embedding_vector is not None:\r\n",
        "        embedding_matrix[i] = embedding_vector"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "400000it [00:11, 33921.63it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8RDrP4xKabR"
      },
      "source": [
        "## <font color='blue'>**Implement custom encoder decoder**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A45uc0JILMlV"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cex2XfCLOew"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim,enc_units,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.enc_units= enc_units\n",
        "        self.embedding= Embedding(self.vocab_size,self.embedding_dim,input_length=self.input_length)\n",
        "        self.lstm     = LSTM(self.enc_units,return_state=True,return_sequences=True)\n",
        "            \n",
        "\n",
        "    def call(self, input_sequence, initial_states,training=True):\n",
        "        embedding          = self.embedding(input_sequence)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(embedding)\n",
        "        return (self.lstm_output, self.lstm_state_h,self.lstm_state_c)\n",
        "    \n",
        "\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "        return (tf.zeros((batch_size,self.enc_units)),tf.zeros((batch_size,self.enc_units)))\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EtbOI3VwLOe0"
      },
      "source": [
        "<font color='orange'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziSqOgmhLOe1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51a15182-4e42-4d12-95e3-a5eed08db20f"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    #Intialzing encoder \n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    #Intializing encoder initial states\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    \n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "  \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1ES1-sJLOe4"
      },
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim, dec_units,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.dec_units = dec_units\n",
        "        self.input_length = input_length\n",
        "        self.embedding    = Embedding(input_dim=self.vocab_size, output_dim=self.embedding_dim, input_length=self.input_length, name=\"embedding_layer_decoder\", trainable=True)\n",
        "        self.lstm         = LSTM(self.dec_units,return_state=True,return_sequences=True)\n",
        "\n",
        "    def call(self, target_sentances, states):\n",
        "        embedding = self.embedding(target_sentances)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(embedding,initial_state=states)\n",
        "        return (self.lstm_output, self.lstm_state_h,self.lstm_state_c)\n",
        "        \n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-I0SUbLOe8"
      },
      "source": [
        "<font color='orange'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0B0gokgKLOe8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "896deaae-8a19-4c3a-ce75-e3a2b3ff15d4"
      },
      "source": [
        "def grader_decoder():\n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    states=[state_h,state_c]\n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, dec_units,input_length )\n",
        "    output,_,_=decoder(target_sentences, states)\n",
        "    assert(output.shape==(batch_size,input_length,dec_units))\n",
        "    return True\n",
        "print(grader_decoder())\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FxfBHRsU2VfO"
      },
      "source": [
        "class Dataset:\r\n",
        "    def __init__(self, data, tknizer_ita, tknizer_eng, max_len):\r\n",
        "        self.encoder_inps = data['italian'].values\r\n",
        "        self.decoder_inps = data['english_inp'].values\r\n",
        "        self.decoder_outs = data['english_out'].values\r\n",
        "        self.tknizer_eng = tknizer_eng\r\n",
        "        self.tknizer_ita = tknizer_ita\r\n",
        "        self.max_len = max_len\r\n",
        "\r\n",
        "    def __getitem__(self, i):\r\n",
        "        self.encoder_seq = self.tknizer_ita.texts_to_sequences([self.encoder_inps[i]]) # need to pass list of values\r\n",
        "        self.decoder_inp_seq = self.tknizer_eng.texts_to_sequences([self.decoder_inps[i]])\r\n",
        "        self.decoder_out_seq = self.tknizer_eng.texts_to_sequences([self.decoder_outs[i]])\r\n",
        "\r\n",
        "        self.encoder_seq = pad_sequences(self.encoder_seq, maxlen=self.max_len, dtype='int32', padding='post')\r\n",
        "        self.decoder_inp_seq = pad_sequences(self.decoder_inp_seq, maxlen=self.max_len, dtype='int32', padding='post')\r\n",
        "        self.decoder_out_seq = pad_sequences(self.decoder_out_seq, maxlen=self.max_len, dtype='int32', padding='post')\r\n",
        "        return self.encoder_seq, self.decoder_inp_seq, self.decoder_out_seq\r\n",
        "\r\n",
        "    def __len__(self): # your model.fit_gen requires this function\r\n",
        "        return len(self.encoder_inps)\r\n",
        "\r\n",
        "    \r\n",
        "class Dataloder(tf.keras.utils.Sequence):    \r\n",
        "    def __init__(self, dataset, batch_size=1):\r\n",
        "        self.dataset = dataset\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.indexes = np.arange(len(self.dataset.encoder_inps))\r\n",
        "\r\n",
        "\r\n",
        "    def __getitem__(self, i):\r\n",
        "        start = i * self.batch_size\r\n",
        "        stop = (i + 1) * self.batch_size\r\n",
        "        data = []\r\n",
        "        for j in range(start, stop):\r\n",
        "            data.append(self.dataset[j])\r\n",
        "\r\n",
        "        batch = [np.squeeze(np.stack(samples, axis=1), axis=0) for samples in zip(*data)]\r\n",
        "        # we are creating data like ([italian, english_inp], english_out) these are already converted into seq\r\n",
        "        return tuple([[batch[0],batch[1]],batch[2]])\r\n",
        "\r\n",
        "    def __len__(self):  # your model.fit_gen requires this function\r\n",
        "        return len(self.indexes) // self.batch_size\r\n",
        "\r\n",
        "    def on_epoch_end(self):\r\n",
        "        self.indexes = np.random.permutation(self.indexes)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cHddYxuc2Xm1"
      },
      "source": [
        "train_dataset = Dataset(train, tknizer_ita, tknizer_eng, 20)\r\n",
        "test_dataset  = Dataset(validation, tknizer_ita, tknizer_eng, 20)\r\n",
        "\r\n",
        "train_dataloader = Dataloder(train_dataset, batch_size=1024)\r\n",
        "test_dataloader = Dataloder(test_dataset, batch_size=1024)\r\n"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o90a7T2gYsWB"
      },
      "source": [
        "start=tknizer_eng.word_index['<start>']"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bpFa-HDt2bRV"
      },
      "source": [
        "class Encoder_Decoder(Model):\r\n",
        "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size):\r\n",
        "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\r\n",
        "        self.encoder = Encoder(vocab_size=vocab_size_ita+1, embedding_dim=50, input_length=encoder_inputs_length, enc_units=256)\r\n",
        "        self.encoder.trainable=True\r\n",
        "        self.decoder = Decoder(vocab_size=vocab_size_eng+1, embedding_dim=100, input_length=decoder_inputs_length, dec_units=256)\r\n",
        "        self.decoder.trainable=True\r\n",
        "        self.dense   = Dense(output_vocab_size, activation='softmax')\r\n",
        "        \r\n",
        "        \r\n",
        "    def call(self, data):\r\n",
        "        input,output = data[0], data[1]\r\n",
        "        initial_state=self.encoder.initialize_states(batch_size)\r\n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\r\n",
        "        decoder_output,_,_                   = self.decoder(output,states=[encoder_h, encoder_c])\r\n",
        "        output                               = self.dense(decoder_output)\r\n",
        "        return output"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIvYMSoH2xRv",
        "outputId": "0668b5d0-65fa-466a-ba9c-cbbe6dfe3fa4"
      },
      "source": [
        "model  = Encoder_Decoder(encoder_inputs_length=20,decoder_inputs_length=20,output_vocab_size=vocab_size_eng)\r\n",
        "optimizer = tf.keras.optimizers.Adam()\r\n",
        "model.compile(optimizer=optimizer,loss='sparse_categorical_crossentropy')\r\n",
        "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\r\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\r\n",
        "batch_size=1024\r\n",
        "train_steps=train.shape[0]//1024\r\n",
        "valid_steps=validation.shape[0]//1024\r\n",
        "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data= test_dataloader, validation_steps=valid_steps,callbacks=tensorboard_callback)\r\n",
        "model.summary()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "268/268 [==============================] - 126s 468ms/step - loss: 3.4921 - val_loss: 1.6614\n",
            "Epoch 2/30\n",
            "268/268 [==============================] - 124s 463ms/step - loss: 1.6072 - val_loss: 1.4633\n",
            "Epoch 3/30\n",
            "268/268 [==============================] - 128s 477ms/step - loss: 1.4133 - val_loss: 1.2810\n",
            "Epoch 4/30\n",
            "268/268 [==============================] - 127s 474ms/step - loss: 1.2501 - val_loss: 1.1804\n",
            "Epoch 5/30\n",
            "268/268 [==============================] - 129s 481ms/step - loss: 1.1367 - val_loss: 1.0677\n",
            "Epoch 6/30\n",
            "268/268 [==============================] - 130s 483ms/step - loss: 1.0304 - val_loss: 0.9767\n",
            "Epoch 7/30\n",
            "268/268 [==============================] - 130s 486ms/step - loss: 0.9377 - val_loss: 0.8976\n",
            "Epoch 8/30\n",
            "268/268 [==============================] - 126s 470ms/step - loss: 0.8543 - val_loss: 0.8227\n",
            "Epoch 9/30\n",
            "268/268 [==============================] - 127s 475ms/step - loss: 0.7705 - val_loss: 0.7493\n",
            "Epoch 10/30\n",
            "268/268 [==============================] - 128s 476ms/step - loss: 0.6920 - val_loss: 0.6802\n",
            "Epoch 11/30\n",
            "268/268 [==============================] - 127s 475ms/step - loss: 0.6176 - val_loss: 0.6190\n",
            "Epoch 12/30\n",
            "268/268 [==============================] - 126s 471ms/step - loss: 0.5526 - val_loss: 0.5653\n",
            "Epoch 13/30\n",
            "268/268 [==============================] - 128s 479ms/step - loss: 0.4922 - val_loss: 0.5173\n",
            "Epoch 14/30\n",
            "268/268 [==============================] - 127s 475ms/step - loss: 0.4415 - val_loss: 0.4752\n",
            "Epoch 15/30\n",
            "268/268 [==============================] - 126s 470ms/step - loss: 0.3949 - val_loss: 0.4403\n",
            "Epoch 16/30\n",
            "268/268 [==============================] - 128s 479ms/step - loss: 0.3541 - val_loss: 0.4115\n",
            "Epoch 17/30\n",
            "268/268 [==============================] - 128s 479ms/step - loss: 0.3182 - val_loss: 0.3832\n",
            "Epoch 18/30\n",
            "268/268 [==============================] - 127s 474ms/step - loss: 0.2879 - val_loss: 0.3646\n",
            "Epoch 19/30\n",
            "268/268 [==============================] - 127s 472ms/step - loss: 0.2619 - val_loss: 0.3444\n",
            "Epoch 20/30\n",
            "268/268 [==============================] - 128s 478ms/step - loss: 0.2404 - val_loss: 0.3287\n",
            "Epoch 21/30\n",
            "268/268 [==============================] - 129s 482ms/step - loss: 0.2202 - val_loss: 0.3126\n",
            "Epoch 22/30\n",
            "268/268 [==============================] - 128s 479ms/step - loss: 0.2029 - val_loss: 0.3015\n",
            "Epoch 23/30\n",
            "268/268 [==============================] - 128s 478ms/step - loss: 0.1879 - val_loss: 0.2912\n",
            "Epoch 24/30\n",
            "268/268 [==============================] - 130s 484ms/step - loss: 0.1736 - val_loss: 0.2824\n",
            "Epoch 25/30\n",
            "268/268 [==============================] - 130s 484ms/step - loss: 0.1626 - val_loss: 0.2758\n",
            "Epoch 26/30\n",
            "268/268 [==============================] - 129s 482ms/step - loss: 0.1513 - val_loss: 0.2684\n",
            "Epoch 27/30\n",
            "268/268 [==============================] - 126s 470ms/step - loss: 0.1424 - val_loss: 0.2618\n",
            "Epoch 28/30\n",
            "268/268 [==============================] - 129s 481ms/step - loss: 0.1328 - val_loss: 0.2568\n",
            "Epoch 29/30\n",
            "268/268 [==============================] - 127s 475ms/step - loss: 0.1252 - val_loss: 0.2519\n",
            "Epoch 30/30\n",
            "268/268 [==============================] - 128s 477ms/step - loss: 0.1182 - val_loss: 0.2481\n",
            "Model: \"encoder__decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_1 (Encoder)          multiple                  1624818   \n",
            "_________________________________________________________________\n",
            "decoder_1 (Decoder)          multiple                  1651068   \n",
            "_________________________________________________________________\n",
            "dense (Dense)                multiple                  3303478   \n",
            "=================================================================\n",
            "Total params: 6,579,364\n",
            "Trainable params: 6,579,364\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pcfOmT_j8E4Q"
      },
      "source": [
        "tensorboard --logdir=./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SkARSlZgLOfE"
      },
      "source": [
        "def predict(input_sentence):\n",
        " encoded                 = tknizer_ita.texts_to_sequences([input_sentence])\n",
        " encoded                 = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=20, dtype='int',padding='post'))\n",
        " initial_state           = model.layers[0].initialize_states(batch_size=1)\n",
        " encoder_outputs, h , c  = model.layers[0](encoded,initial_state)\n",
        " \n",
        " start                   = tknizer_eng.word_index['<start>']\n",
        " output_sentence=[]\n",
        " \n",
        " for i in range(20):\n",
        "   decoder_output, h, c  = model.layers[1](tf.expand_dims([start],axis=1),states=[h ,c])\n",
        "   dense_output          = model.layers[2](decoder_output)\n",
        "   word_index            = tf.math.argmax(*dense_output,1)\n",
        "   english_word          = tknizer_eng.index_word[word_index.numpy()[0]]\n",
        "   start                 = word_index.numpy()[0]\n",
        "   output_sentence.append(english_word)\n",
        "\n",
        "   if english_word=='<end>':\n",
        "     break\n",
        "     \n",
        " return \" \".join(output_sentence)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "996pFO8BLOfG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4cdef7b3-24f4-4d95-e82f-6bba3fb5340f"
      },
      "source": [
        "Bleu=[]\n",
        "print(len(validation['italian']))\n",
        "\n",
        "for i in np.random.choice(np.arange(len(validation['italian'])),size=1000,replace=False):\n",
        "  Bleu.append(nltk.translate.bleu_score.sentence_bleu(validation['english_out'].iloc[i],predict(validation['italian'].iloc[i])))\n",
        "print(sum(Bleu)/1000)\n",
        "\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "for i in np.random.choice(np.arange(len(validation['italian'])),size=10,replace=False):\n",
        "  print('Italian\\t',validation['italian'].iloc[i])\n",
        "  print('English_out\\t',validation['english_out'].iloc[i])\n",
        "  print('Predicted\\t',predict(validation['italian'].iloc[i]))\n",
        "  print('\\n')"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.834200935079292\n",
            "Italian\t posso parlare adesso\n",
            "English_out\t can i talk now <end>\n",
            "Predicted\t can i talk now <end>\n",
            "\n",
            "\n",
            "Italian\t tom è svenuto\n",
            "English_out\t tom is fainted <end>\n",
            "Predicted\t tom is unconscious <end>\n",
            "\n",
            "\n",
            "Italian\t perché tom abbraccerebbe mary\n",
            "English_out\t why would tom hug mary <end>\n",
            "Predicted\t why would tom hug mary <end>\n",
            "\n",
            "\n",
            "Italian\t ha un buon sapore\n",
            "English_out\t does it taste good <end>\n",
            "Predicted\t does it taste good <end>\n",
            "\n",
            "\n",
            "Italian\t la sua stanza è pulita\n",
            "English_out\t is your room clean <end>\n",
            "Predicted\t is your room clean <end>\n",
            "\n",
            "\n",
            "Italian\t tom ha bevuto un altro sorso di caffè\n",
            "English_out\t tom took another sip of coffee <end>\n",
            "Predicted\t tom had another sip of beer <end>\n",
            "\n",
            "\n",
            "Italian\t tom mi ha lasciato guidare la sua auto\n",
            "English_out\t tom let me drive his car <end>\n",
            "Predicted\t tom let me drive his car <end>\n",
            "\n",
            "\n",
            "Italian\t voi avete bevuto tre tazze di caffè\n",
            "English_out\t you have drunk three cups of coffee <end>\n",
            "Predicted\t you have drunk three cups of coffee <end>\n",
            "\n",
            "\n",
            "Italian\t il mio orologio perde due minuti al giorno\n",
            "English_out\t my watch loses two minutes a day <end>\n",
            "Predicted\t my watch two leaves a day <end>\n",
            "\n",
            "\n",
            "Italian\t lui mi ha sparato\n",
            "English_out\t he shot at me <end>\n",
            "Predicted\t he shot me <end>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CxWFDxZXLOfJ"
      },
      "source": [
        " "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZhX3K9GLOfJ"
      },
      "source": [
        "## Task -2: Including Attention mechanisum"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3d7GeBMGbsJ"
      },
      "source": [
        "1. Use the preprocessed data from Task-1\n",
        "\n",
        "2. You have to implement an Encoder and Decoder architecture with  \n",
        "attention as discussed in the reference notebook.\n",
        "\n",
        "    * Encoder   - with 1 layer LSTM <br>\n",
        "    * Decoder   - with 1 layer LSTM<br>\n",
        "    * attention -  (Please refer the <a href= 'https://drive.google.com/file/d/1z_bnc-3aubKawbR6q8wyI6Mh5ho2R1aZ/view?usp=sharing'>**reference notebook**</a> to know more about the attention mechanism.)\n",
        "3. In Global attention, we have 3 types of scoring functions(as discussed in the reference notebook).\n",
        " As a part of this assignment **you need to create 3 models for each scoring function**\n",
        "<img src='https://i.imgur.com/iD2jZo3.png'>\n",
        "\n",
        "    * In model 1 you need to implemnt \"dot\" score function\n",
        "    * In model 2 you need to implemnt \"general\" score function\n",
        "    * In model 3 you need to implemnt \"concat\" score function.<br>\n",
        "    \n",
        " **Please do add the markdown titles for each model so that we can have a better look at the code and verify.**\n",
        "4. It is mandatory to train the model with simple model.fit() only, Donot train the model with custom GradientTape()\n",
        "\n",
        "5. Using attention weights, you can plot the attention plots, \n",
        "please plot those for 2-3 examples. You can check about those in <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\">this</a>\n",
        "\n",
        "6. The attention layer has to be written by yourself only. \n",
        "The main objective of this assignment is to read and implement a paper on yourself so please do it yourself.  \n",
        "\n",
        "7. Please implement the class **onestepdecoder** as mentioned in the assignment instructions.\n",
        "\n",
        "8. You can use any tf.Keras highlevel API's to build and train the models. \n",
        " Check the reference notebook for better understanding.\n",
        "\n",
        "9. Use BLEU score as metric to evaluate your model. You can use any loss function you need.\n",
        "\n",
        "10. You have to use Tensorboard to plot the Graph, Scores and histograms of gradients. \n",
        "\n",
        "11. Resources:\n",
        "    a. Check the reference notebook\n",
        "    b. <a href=\"https://jalammar.github.io/visualizing-neural-machine-translation-mechanics-of-seq2seq-models-with-attention/\">Resource 1</a>\n",
        "    c. <a href=\"https://www.tensorflow.org/tutorials/text/nmt_with_attention\">Resource 2</a>\n",
        "    d. <a href=\"https://stackoverflow.com/questions/44238154/what-is-the-difference-between-luong-attention-and-bahdanau-attention#:~:text=Luong%20attention%20used%20top%20hidden,hidden%20state%20at%20time%20t.\">Resource 3</a>\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU4KIsGxLOfK"
      },
      "source": [
        "### <font color='blue'>**Implement custom encoder decoder and attention layers**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TMm3ADQDLOfK"
      },
      "source": [
        "<font color='blue'>**Encoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lx_5NA24KzRp"
      },
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, vocab_size, embedding_dim,enc_units,input_length):\n",
        "        super().__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.input_length = input_length\n",
        "        self.enc_units= enc_units\n",
        "\n",
        "    def build(self,_):\n",
        "        self.embedding= Embedding(self.vocab_size,self.embedding_dim,input_length=self.input_length)\n",
        "        self.lstm     = LSTM(self.enc_units,return_state=True,return_sequences=True)\n",
        "            \n",
        "    def call(self, input_sequence, initial_states,training=True):\n",
        "        embedding          = self.embedding(input_sequence)\n",
        "        self.lstm_output, self.lstm_state_h,self.lstm_state_c = self.lstm(embedding)\n",
        "        return (self.lstm_output, self.lstm_state_h,self.lstm_state_c)\n",
        "    \n",
        "    def initialize_states(self,batch_size):\n",
        "        return (tf.zeros((batch_size,self.enc_units)),tf.zeros((batch_size,self.enc_units)))\n",
        "\n"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ub9aN-hK244"
      },
      "source": [
        "<font color='cyan'>**Grader function - 1**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wRoe65b9LB0D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e950009-c961-4c97-a751-06979e86b65c"
      },
      "source": [
        "def grader_check_encoder():\n",
        "    \n",
        "    '''\n",
        "        vocab-size: Unique words of the input language,\n",
        "        embedding_size: output embedding dimension for each word after embedding layer,\n",
        "        lstm_size: Number of lstm units in encoder,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    vocab_size=10\n",
        "    embedding_size=20\n",
        "    lstm_size=32\n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    encoder=Encoder(vocab_size,embedding_size,lstm_size,input_length)\n",
        "    input_sequence=tf.random.uniform(shape=[batch_size,input_length],maxval=vocab_size,minval=0,dtype=tf.int32)\n",
        "    initial_state=encoder.initialize_states(batch_size)\n",
        "    encoder_output,state_h,state_c=encoder(input_sequence,initial_state)\n",
        "    \n",
        "    assert(encoder_output.shape==(batch_size,input_length,lstm_size) and state_h.shape==(batch_size,lstm_size) and state_c.shape==(batch_size,lstm_size))\n",
        "    return True\n",
        "print(grader_check_encoder())"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXn278lhLYRM"
      },
      "source": [
        "<font color='blue'>**Attention**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab5SNdPZLlur"
      },
      "source": [
        "#https://stackoverflow.com/questions/47157692/how-does-reduce-sum-work-in-tensorflow\n",
        "class Attention(tf.keras.layers.Layer):\n",
        "  def __init__(self,scoring_function, att_units):\n",
        "    super().__init__()\n",
        "    self.scoring_function=scoring_function\n",
        "    if self.scoring_function=='dot':\n",
        "      pass\n",
        "      \n",
        "    if scoring_function == 'general':\n",
        "      self.wa = tf.keras.layers.Dense(att_units)\n",
        "\n",
        "    elif scoring_function == 'concat':\n",
        "      self.wa = tf.keras.layers.Dense(att_units)\n",
        "      self.va = tf.keras.layers.Dense(1)\n",
        "\n",
        "\n",
        "  def call(self,decoder_hidden_state,encoder_output):\n",
        "    decoder_hidden_state=tf.expand_dims(decoder_hidden_state,axis=1)\n",
        "    if self.scoring_function == 'dot':\n",
        "      score = tf.matmul(encoder_output, decoder_hidden_state, transpose_b=True)\n",
        "      \n",
        "    elif self.scoring_function == 'general':\n",
        "      score = tf.matmul(self.wa(encoder_output), decoder_hidden_state, transpose_b=True)\n",
        "      \n",
        "    elif self.scoring_function == 'concat':\n",
        "      score = self.va(tf.nn.tanh(self.wa(decoder_hidden_state+encoder_output)))\n",
        "      \n",
        "    \n",
        "    attention_weights = tf.nn.softmax(score, axis=1)#refered\n",
        "    \n",
        "    \n",
        "    context = tf.reduce_sum(attention_weights*encoder_output , axis=1)#refered\n",
        "    \n",
        "    \n",
        "    return context, attention_weights"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ExQDlxI9LuqK"
      },
      "source": [
        "<font color='cyan'>**Grader function - 2**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "51x50h_TLrl9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cd4c83ce-f116-48c7-8fec-c483940c1e17"
      },
      "source": [
        "def grader_check_attention(scoring_fun):\n",
        "    \n",
        "    ''' \n",
        "        att_units: Used in matrix multiplications for scoring functions,\n",
        "        input_length: Length of the input sentence,\n",
        "        batch_size\n",
        "    '''\n",
        "    \n",
        "    input_length=10\n",
        "    batch_size=16\n",
        "    att_units=32\n",
        "    \n",
        "    state_h=tf.random.uniform(shape=[batch_size,att_units])\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,att_units])\n",
        "    attention=Attention(scoring_fun,att_units)\n",
        "    context_vector,attention_weights=attention(state_h,encoder_output)\n",
        "    assert(context_vector.shape==(batch_size,att_units) and attention_weights.shape==(batch_size,input_length,1))\n",
        "    return True\n",
        "print(grader_check_attention('dot'))\n",
        "print(grader_check_attention('general'))\n",
        "print(grader_check_attention('concat'))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ic-FNEbfL2DN"
      },
      "source": [
        "<font color='blue'>**OneStepDecoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kc8m7lmOL097"
      },
      "source": [
        "class One_Step_Decoder(tf.keras.Model):\n",
        "  def __init__(self,tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "    super().__init__()\n",
        "    self.tar_vocab_size=tar_vocab_size\n",
        "    self.embedding_dim=embedding_dim\n",
        "    self.input_length=input_length\n",
        "    self.dec_units=dec_units\n",
        "    self.score_fun=score_fun\n",
        "    self.att_units=att_units\n",
        "    self.attention=Attention('dot',self.att_units)\n",
        "    self.embedding = tf.keras.layers.Embedding(input_dim=self.tar_vocab_size, output_dim=embedding_dim)\n",
        "    self.lstm = tf.keras.layers.LSTM(self.dec_units, return_sequences=True, return_state=True)\n",
        "    self.dense1 = tf.keras.layers.Dense(self.tar_vocab_size)\n",
        "\n",
        "\n",
        "  def call(self,input_to_decoder, encoder_output, state_h,state_c):\n",
        "    embeddings=self.embedding(input_to_decoder)\n",
        "    context_vector,attention_weights=self.attention(state_h,encoder_output)\n",
        "    # print(context_vector.shape)\n",
        "    # print(attention_weights.shape)\n",
        "    concat_layers = tf.concat([tf.expand_dims(context_vector, 1), embeddings], axis=-1)\n",
        "    # print(tf.expand_dims(context_vector, 1).shape)\n",
        "    # print(embeddings.shape)\n",
        "    # print(concat_layers.shape)\n",
        "    output, state_h,state_c = self.lstm(concat_layers,[state_h,state_c])#refered\n",
        "    output=tf.reshape(output,(-1,output.shape[2]))#refered\n",
        "    output_dense=self.dense1(output)\n",
        "\n",
        "    return output_dense,state_h,state_c,attention_weights,context_vector"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R_I8I4EIMAXq"
      },
      "source": [
        "<font color='cyan'>**Grader function - 3**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uLEXhChnMC1k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9f5c18e3-16c0-4f10-e14b-8b49ab8d711c"
      },
      "source": [
        "def grader_onestepdecoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        tar_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    tar_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=10\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    onestepdecoder=One_Step_Decoder(tar_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    input_to_decoder=tf.random.uniform(shape=(batch_size,1),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    output,state_h,state_c,attention_weights,context_vector=onestepdecoder(input_to_decoder,encoder_output,state_h,state_c)\n",
        "    assert(output.shape==(batch_size,tar_vocab_size))\n",
        "    assert(state_h.shape==(batch_size,dec_units))\n",
        "    assert(state_c.shape==(batch_size,dec_units))\n",
        "    assert(attention_weights.shape==(batch_size,input_length,1))\n",
        "    assert(context_vector.shape==(batch_size,dec_units))\n",
        "    return True\n",
        "    \n",
        "print(grader_onestepdecoder('dot'))\n",
        "print(grader_onestepdecoder('general'))\n",
        "print(grader_onestepdecoder('concat'))\n",
        "    "
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6FHrurjUMGAi"
      },
      "source": [
        "<font color='blue'>**Decoder**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NV-x31rj6Hc4"
      },
      "source": [
        "class Decoder(tf.keras.Model):\n",
        "    def __init__(self,out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units):\n",
        "      #Intialize necessary variables and create an object from the class onestepdecoder\n",
        "      super().__init__()\n",
        "      self.out_vocab_size  = out_vocab_size\n",
        "      self.embedding_dim   = embedding_dim\n",
        "      self.input_length    = input_length\n",
        "      self.dec_units       = dec_units\n",
        "      self.score_fun       = score_fun\n",
        "      self.att_units       = att_units\n",
        "      self.One_Step_Decoder= One_Step_Decoder(self.out_vocab_size, self.embedding_dim, self.input_length, self.dec_units ,self.score_fun ,self.att_units)\n",
        "        \n",
        "    def call(self, input_to_decoder,encoder_output,decoder_hidden_state,decoder_cell_state ):\n",
        "\n",
        "        #Initialize an empty Tensor array, that will store the outputs at each and every time step\n",
        "        #Create a tensor array as shown in the reference notebook\n",
        "        \n",
        "        #Iterate till the length of the decoder input\n",
        "            # Call onestepdecoder for each token in decoder_input\n",
        "            # Store the output in tensorarray\n",
        "        # Return the tensor array\n",
        "        \n",
        "        self.input_to_decoder      = input_to_decoder\n",
        "        self.encoder_output        = encoder_output\n",
        "        self.decoder_hidden_state  = decoder_hidden_state\n",
        "        self.decoder_cell_state    = decoder_cell_state\n",
        "        all_outputs= tf.TensorArray(tf.float32, size=input_to_decoder.shape[1])\n",
        "        for timestep in range(input_to_decoder.shape[-1]):\n",
        "          output_dense,decoder_hidden_state,decoder_cell_state,attention_weights,context_vector = self.One_Step_Decoder(input_to_decoder[:,timestep:timestep+1], encoder_output, decoder_hidden_state,decoder_cell_state)\n",
        "          all_outputs = all_outputs.write(timestep,output_dense)\n",
        "        all_outputs = tf.transpose(all_outputs.stack(),[1,0,2])\n",
        "        return all_outputs\n",
        "\n",
        "      \n",
        "        \n",
        "        \n",
        "    "
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FxrL-P8bMJH6"
      },
      "source": [
        "<font color='cyan'>**Grader function - 4**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtbx6onFMJXb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab5ebc6a-058c-4857-cab3-626dd9ee1889"
      },
      "source": [
        "def grader_decoder(score_fun):\n",
        "    \n",
        "    '''\n",
        "        out_vocab_size: Unique words of the target language,\n",
        "        embedding_dim: output embedding dimension for each word after embedding layer,\n",
        "        dec_units: Number of lstm units in decoder,\n",
        "        att_units: Used in matrix multiplications for scoring functions in attention class,\n",
        "        input_length: Length of the target sentence,\n",
        "        batch_size\n",
        "        \n",
        "    \n",
        "    '''\n",
        "    \n",
        "    out_vocab_size=13 \n",
        "    embedding_dim=12 \n",
        "    input_length=11\n",
        "    dec_units=16 \n",
        "    att_units=16\n",
        "    batch_size=32\n",
        "    \n",
        "    target_sentences=tf.random.uniform(shape=(batch_size,input_length),maxval=10,minval=0,dtype=tf.int32)\n",
        "    encoder_output=tf.random.uniform(shape=[batch_size,input_length,dec_units])\n",
        "    state_h=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    state_c=tf.random.uniform(shape=[batch_size,dec_units])\n",
        "    \n",
        "    decoder=Decoder(out_vocab_size, embedding_dim, input_length, dec_units ,score_fun ,att_units)\n",
        "    output=decoder(target_sentences,encoder_output, state_h, state_c)\n",
        "    assert(output.shape==(batch_size,input_length,out_vocab_size))\n",
        "    return True\n",
        "print(grader_decoder('dot'))\n",
        "print(grader_decoder('general'))\n",
        "print(grader_decoder('concat'))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "True\n",
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fC1T1EOoMTqC"
      },
      "source": [
        "<font color='blue'>**Encoder Decoder model**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FfqBIe20MT3D"
      },
      "source": [
        "class encoder_decoder(tf.keras.Model):\n",
        "    def __init__(self, encoder_inputs_length,decoder_inputs_length, output_vocab_size,score_fun,att_units):\n",
        "        super().__init__() # https://stackoverflow.com/a/27134600/4084039\n",
        "        self.encoder_inputs_length=encoder_inputs_length\n",
        "        self.decoder_inputs_length=decoder_inputs_length\n",
        "        self.output_vocab_size=output_vocab_size\n",
        "        self.score_fun=score_fun\n",
        "        self.att_units=att_units\n",
        "        \n",
        "        \n",
        "    def build(self,_):\n",
        "        self.encoder = Encoder(vocab_size=vocab_size_ita+1, embedding_dim=50, input_length=self.encoder_inputs_length, enc_units=256)\n",
        "        self.encoder.trainable=True\n",
        "        self.decoder = Decoder(out_vocab_size=vocab_size_eng+1, embedding_dim=100, input_length=self.decoder_inputs_length, dec_units=256 ,score_fun=self.score_fun ,att_units=self.att_units)\n",
        "        self.decoder.trainable=True\n",
        "        \n",
        "        \n",
        "        \n",
        "    def call(self, data):\n",
        "        input,output = data[0], data[1]\n",
        "        initial_state=self.encoder.initialize_states(batch_size)\n",
        "        encoder_output, encoder_h, encoder_c = self.encoder(input,initial_state)\n",
        "        output                       = self.decoder(output,encoder_output,encoder_h, encoder_c)\n",
        "\n",
        "        return output\n"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WVRxB-FDMJWL"
      },
      "source": [
        "<font color='blue'>**Custom loss function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QY_3izrXMs8y"
      },
      "source": [
        "def custom_lossfunction(targets,logits):\n",
        "  optimizer = tf.keras.optimizers.Adam()\n",
        "  loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction='none')\n",
        "  mask = tf.math.logical_not(tf.math.equal(targets, 0))\n",
        "  loss_ = loss_object(targets,logits)\n",
        "\n",
        "  mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "  loss_ *= mask\n",
        "\n",
        "  return tf.reduce_mean(loss_)\n",
        "  # Custom loss function that will not consider the loss for padded zeros.\n",
        "  # Refer https://www.tensorflow.org/tutorials/text/nmt_with_attention#define_the_optimizer_and_the_loss_function\n"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QlbWAqNNlqe"
      },
      "source": [
        "<font color='blue'>**Training**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wqtZUQF2NuZE"
      },
      "source": [
        "Implement dot function here."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fgyWwZWeMxGQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "383edce2-e30e-4afd-9c3e-2d8c2c5ae184"
      },
      "source": [
        "# Implement teacher forcing while training your model. You can do it two ways.\n",
        "# Prepare your data, encoder_input,decoder_input and decoder_output\n",
        "# if decoder input is \n",
        "# <start> Hi how are you\n",
        "# decoder output should be\n",
        "# Hi How are you <end>\n",
        "# i.e when you have send <start>-- decoder predicted Hi, 'Hi' decoder predicted 'How' .. e.t.c\n",
        "\n",
        "# or\n",
        " \n",
        "# model.fit([train_ita,train_eng],train_eng[:,1:]..)\n",
        "# Note: If you follow this approach some grader functions might return false and this is fine.\n",
        "model  = encoder_decoder(encoder_inputs_length=20,decoder_inputs_length=20,output_vocab_size=vocab_size_eng,score_fun='dot',att_units=16)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,loss=custom_lossfunction)\n",
        "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "batch_size=1024\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data= test_dataloader, validation_steps=valid_steps,callbacks=tensorboard_callback)\n",
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "268/268 [==============================] - 211s 785ms/step - loss: 2.0669 - val_loss: 1.6611\n",
            "Epoch 2/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 1.6279 - val_loss: 1.4910\n",
            "Epoch 3/30\n",
            "268/268 [==============================] - 209s 781ms/step - loss: 1.4356 - val_loss: 1.2678\n",
            "Epoch 4/30\n",
            "268/268 [==============================] - 210s 785ms/step - loss: 1.2196 - val_loss: 1.1095\n",
            "Epoch 5/30\n",
            "268/268 [==============================] - 211s 786ms/step - loss: 1.0641 - val_loss: 0.9819\n",
            "Epoch 6/30\n",
            "268/268 [==============================] - 212s 791ms/step - loss: 0.9364 - val_loss: 0.8744\n",
            "Epoch 7/30\n",
            "268/268 [==============================] - 211s 787ms/step - loss: 0.8231 - val_loss: 0.7792\n",
            "Epoch 8/30\n",
            "268/268 [==============================] - 211s 787ms/step - loss: 0.7251 - val_loss: 0.6929\n",
            "Epoch 9/30\n",
            "268/268 [==============================] - 210s 785ms/step - loss: 0.6329 - val_loss: 0.6157\n",
            "Epoch 10/30\n",
            "268/268 [==============================] - 212s 791ms/step - loss: 0.5500 - val_loss: 0.5464\n",
            "Epoch 11/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 0.4767 - val_loss: 0.4920\n",
            "Epoch 12/30\n",
            "268/268 [==============================] - 208s 776ms/step - loss: 0.4141 - val_loss: 0.4424\n",
            "Epoch 13/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 0.3612 - val_loss: 0.4045\n",
            "Epoch 14/30\n",
            "268/268 [==============================] - 207s 770ms/step - loss: 0.3190 - val_loss: 0.3729\n",
            "Epoch 15/30\n",
            "268/268 [==============================] - 207s 772ms/step - loss: 0.2821 - val_loss: 0.3480\n",
            "Epoch 16/30\n",
            "268/268 [==============================] - 207s 774ms/step - loss: 0.2517 - val_loss: 0.3268\n",
            "Epoch 17/30\n",
            "268/268 [==============================] - 207s 774ms/step - loss: 0.2271 - val_loss: 0.3082\n",
            "Epoch 18/30\n",
            "268/268 [==============================] - 207s 774ms/step - loss: 0.2039 - val_loss: 0.2946\n",
            "Epoch 19/30\n",
            "268/268 [==============================] - 209s 780ms/step - loss: 0.1851 - val_loss: 0.2808\n",
            "Epoch 20/30\n",
            "268/268 [==============================] - 207s 771ms/step - loss: 0.1698 - val_loss: 0.2699\n",
            "Epoch 21/30\n",
            "268/268 [==============================] - 208s 775ms/step - loss: 0.1548 - val_loss: 0.2604\n",
            "Epoch 22/30\n",
            "268/268 [==============================] - 209s 780ms/step - loss: 0.1426 - val_loss: 0.2549\n",
            "Epoch 23/30\n",
            "268/268 [==============================] - 209s 778ms/step - loss: 0.1319 - val_loss: 0.2478\n",
            "Epoch 24/30\n",
            "268/268 [==============================] - 208s 774ms/step - loss: 0.1226 - val_loss: 0.2427\n",
            "Epoch 25/30\n",
            "268/268 [==============================] - 208s 777ms/step - loss: 0.1142 - val_loss: 0.2372\n",
            "Epoch 26/30\n",
            "268/268 [==============================] - 209s 779ms/step - loss: 0.1055 - val_loss: 0.2330\n",
            "Epoch 27/30\n",
            "268/268 [==============================] - 209s 778ms/step - loss: 0.0986 - val_loss: 0.2296\n",
            "Epoch 28/30\n",
            "268/268 [==============================] - 207s 775ms/step - loss: 0.0914 - val_loss: 0.2272\n",
            "Epoch 29/30\n",
            "268/268 [==============================] - 208s 778ms/step - loss: 0.0858 - val_loss: 0.2250\n",
            "Epoch 30/30\n",
            "268/268 [==============================] - 209s 779ms/step - loss: 0.0805 - val_loss: 0.2231\n",
            "Model: \"encoder_decoder\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_3 (Encoder)          multiple                  1624818   \n",
            "_________________________________________________________________\n",
            "decoder_5 (Decoder)          multiple                  5216947   \n",
            "=================================================================\n",
            "Total params: 6,841,765\n",
            "Trainable params: 6,841,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzbuYBCDAL70"
      },
      "source": [
        "tensorboard --logdir=./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6DpC9zlzMcXp"
      },
      "source": [
        "## <font color='blue'>**Inference**</font>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5NhESYyMW_t"
      },
      "source": [
        "<font color='blue'>**Plot attention weights**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkEY7SsBMtrC"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_attention(attention_weights,predicted,sentence):\n",
        "  #Refer: https://www.tensorflow.org/tutorials/text/nmt_with_attention#translate\n",
        "  fig = plt.figure(figsize=(len(sentence.split(' ')),len(predicted.split(' '))))\n",
        "  ax = fig.add_subplot(1, 1, 1)\n",
        "  ax.matshow(attention_weights, cmap='viridis')\n",
        "  fontdict = {'fontsize': 14}\n",
        "  ax.set_xticklabels([''] + sentence.split(' '), fontdict=fontdict, rotation=90)\n",
        "  ax.set_yticklabels([''] + predicted.split(' '), fontdict=fontdict)\n",
        "  ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
        "  plt.show()\n",
        "\n"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e1IhdBrgQYJr"
      },
      "source": [
        "<font color='blue'>**Predict the sentence translation**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ebE4UCTomPD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cb34c83-375b-460d-f620-087bb7292926"
      },
      "source": [
        "len(tknizer_eng.index_word)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "12854"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_XWD86VhGVP"
      },
      "source": [
        "def predict(input_sentence):\r\n",
        "\r\n",
        "  '''\r\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\r\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\r\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\r\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\r\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\r\n",
        "         Save the attention weights\r\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\r\n",
        "  E. Call plot_attention(#params)\r\n",
        "  F. Return the predicted sentence\r\n",
        "  '''\r\n",
        "  encoded              = tknizer_ita.texts_to_sequences([input_sentence])\r\n",
        "  encoded              = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=20, dtype='int',padding='post'))\r\n",
        "  initial_state        = model.layers[0].initialize_states(batch_size=1)\r\n",
        "  encoder_outputs, h , c = model.layers[0](encoded,initial_state)\r\n",
        "  start                = tknizer_eng.word_index['<start>']\r\n",
        "  output_sentence=[]\r\n",
        "  attention_weights_list=[]\r\n",
        "  attention_plot=np.zeros((20,20))\r\n",
        "  for i in range(20):\r\n",
        "   decoder_output = model.layers[1](tf.expand_dims([start],axis=1),encoder_outputs,h,c)\r\n",
        "   output_dense,h,c,attention_weights,context_vector = model.layers[1].layers[0](tf.expand_dims([start],axis=1),encoder_outputs,h,c)\r\n",
        "   word_index=(tf.math.argmax(decoder_output[0][0]))\r\n",
        "   attention_weights = tf.reshape(attention_weights, (1,20))\r\n",
        "   attention_plot[i]=(attention_weights.numpy()[0])\r\n",
        "   english_word=tknizer_eng.index_word[word_index.numpy()]\r\n",
        "   start=word_index.numpy()\r\n",
        "   output_sentence.append(english_word)\r\n",
        "   if english_word=='<end>':\r\n",
        "     break\r\n",
        "  return \" \".join(output_sentence),attention_plot\r\n"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmxIVOOQPWMu"
      },
      "source": [
        "<font color='blue'>**Calculate BLEU score**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0iHiLdROM23l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7662d4cb-f1c8-4cfa-9366-7621bdd69428"
      },
      "source": [
        "#Create an object of your custom model.\n",
        "#Compile and train your model on dot scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "\n",
        "#Sample example\n",
        "import nltk\n",
        "Bleu=[]\n",
        "for i in (np.random.choice(np.arange(len(validation['italian'])),size=1000,replace=False)):\n",
        "  ans,att=predict(validation['italian'].iloc[i])\n",
        "  Bleu.append(nltk.translate.bleu_score.sentence_bleu(validation['english_out'].iloc[i],ans))\n",
        "print(sum(Bleu)/1000)\n",
        "\n",
        "\n",
        "for i in np.random.choice(np.arange(len(validation['italian'])),size=10,replace=False):\n",
        "  ans,att=predict(validation['italian'].iloc[i])\n",
        "  print('Italian\\t',validation['italian'].iloc[i])\n",
        "  print('English_out\\t',validation['english_out'].iloc[i])\n",
        "  print('Predicted\\t',ans)\n",
        "  print('\\n')\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8390026045640984\n",
            "Italian\t tom probabilmente non avrà ancora finito\n",
            "English_out\t tom will not likely be done yet <end>\n",
            "Predicted\t tom will probably not be finished yet <end>\n",
            "\n",
            "\n",
            "Italian\t a tom serve altro\n",
            "English_out\t does tom need anything else <end>\n",
            "Predicted\t tom needs other else <end>\n",
            "\n",
            "\n",
            "Italian\t non lavoreremo domani\n",
            "English_out\t we will not be working tomorrow <end>\n",
            "Predicted\t we will not be working tomorrow <end>\n",
            "\n",
            "\n",
            "Italian\t noi stiamo fuggendo\n",
            "English_out\t we are escaping <end>\n",
            "Predicted\t we are escaping <end>\n",
            "\n",
            "\n",
            "Italian\t sto pulendo la cucina\n",
            "English_out\t i am cleaning the kitchen <end>\n",
            "Predicted\t i am cleaning the kitchen <end>\n",
            "\n",
            "\n",
            "Italian\t firmi su questa linea\n",
            "English_out\t sign on this line <end>\n",
            "Predicted\t sign this line for the official <end>\n",
            "\n",
            "\n",
            "Italian\t mi sposerò\n",
            "English_out\t i am going to get married <end>\n",
            "Predicted\t i am going to marry me <end>\n",
            "\n",
            "\n",
            "Italian\t tom ha dato un bacio in bocca a mary\n",
            "English_out\t tom gave mary a kiss on the mouth <end>\n",
            "Predicted\t tom gave mary a kiss on the mouth <end>\n",
            "\n",
            "\n",
            "Italian\t tom ha scritto più di trenta libri\n",
            "English_out\t tom has written more than thirty books <end>\n",
            "Predicted\t tom has written more books from this month <end>\n",
            "\n",
            "\n",
            "Italian\t più del 40 degli studenti vanno alluniversità\n",
            "English_out\t more than 40 percent of the students go to university <end>\n",
            "Predicted\t more more than 40 percent of the year of france <end>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blo3OFaVp3f2"
      },
      "source": [
        "# !pip install tensorflow-gpu \r\n",
        "# !pip install keras-gpu"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o31VCdTpYXhu"
      },
      "source": [
        "import matplotlib.ticker as ticker"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Tj-QxgWVLIE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 536
        },
        "outputId": "aad24a9d-bb84-402a-cba5-6cc14f7f19a4"
      },
      "source": [
        "norm = np.linalg.norm(np.array(att))\r\n",
        "normal_array = np.array(att)/norm\r\n",
        "attention_plot= np.array(normal_array)\r\n",
        "print(len(validation['italian'].iloc[i].split()))\r\n",
        "plot_attention(attention_plot, ans, validation['italian'].iloc[i])\r\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x792 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWg2ferDQvT3"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for General scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Rh9_w79M5JO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "85e6d2d6-1189-44c6-c092-d12e9f57dd84"
      },
      "source": [
        "#Compile and train your model on general scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "model  = encoder_decoder(encoder_inputs_length=20,decoder_inputs_length=20,output_vocab_size=vocab_size_eng,score_fun='general',att_units=16)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,loss=custom_lossfunction)\n",
        "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "batch_size=1024\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data= test_dataloader, validation_steps=valid_steps,callbacks=tensorboard_callback)\n",
        "model.summary()\n",
        "\n",
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  encoded              = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  encoded              = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=20, dtype='int',padding='post'))\n",
        "  initial_state        = model.layers[0].initialize_states(batch_size=1)\n",
        "  encoder_outputs, h , c = model.layers[0](encoded,initial_state)\n",
        "  start                = tknizer_eng.word_index['<start>']\n",
        "  output_sentence=[]\n",
        "  attention_weights_list=[]\n",
        "  attention_plot=np.zeros((20,20))\n",
        "  for i in range(20):\n",
        "   decoder_output = model.layers[1](tf.expand_dims([start],axis=1),encoder_outputs,h,c)\n",
        "   output_dense,h,c,attention_weights,context_vector = model.layers[1].layers[0](tf.expand_dims([start],axis=1),encoder_outputs,h,c)\n",
        "   word_index=(tf.math.argmax(decoder_output[0][0]))\n",
        "   attention_weights = tf.reshape(attention_weights, (1,20))\n",
        "   attention_plot[i]=(attention_weights.numpy()[0])\n",
        "   english_word=tknizer_eng.index_word[word_index.numpy()]\n",
        "   start=word_index.numpy()\n",
        "   output_sentence.append(english_word)\n",
        "   if english_word=='<end>':\n",
        "     break\n",
        "  return \" \".join(output_sentence),attention_plot\n",
        "\n",
        "Bleu=[]\n",
        "print(len(validation['italian']))\n",
        "for i in np.random.choice(np.arange(len(validation['italian'])),size=1000,replace=False):\n",
        "  ans,att=predict(validation['italian'].iloc[i])\n",
        "  Bleu.append(nltk.translate.bleu_score.sentence_bleu(validation['english_out'].iloc[i],ans))\n",
        "print(sum(Bleu)/1000)\n",
        "\n",
        "\n",
        "for i in np.random.choice(np.arange(len(validation['italian'])),size=10,replace=False):\n",
        "  ans,att=predict(validation['italian'].iloc[i])\n",
        "  print('Italian\\t',validation['italian'].iloc[i])\n",
        "  print('English_out\\t',validation['english_out'].iloc[i])\n",
        "  print('Predicted\\t',ans)\n",
        "  print('\\n')"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "268/268 [==============================] - 209s 780ms/step - loss: 2.0704 - val_loss: 1.6700\n",
            "Epoch 2/30\n",
            "268/268 [==============================] - 209s 778ms/step - loss: 1.6584 - val_loss: 1.5848\n",
            "Epoch 3/30\n",
            "268/268 [==============================] - 208s 777ms/step - loss: 1.5486 - val_loss: 1.3853\n",
            "Epoch 4/30\n",
            "268/268 [==============================] - 209s 780ms/step - loss: 1.3240 - val_loss: 1.1586\n",
            "Epoch 5/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 1.1054 - val_loss: 0.9922\n",
            "Epoch 6/30\n",
            "268/268 [==============================] - 210s 784ms/step - loss: 0.9454 - val_loss: 0.8699\n",
            "Epoch 7/30\n",
            "268/268 [==============================] - 209s 780ms/step - loss: 0.8204 - val_loss: 0.7618\n",
            "Epoch 8/30\n",
            "268/268 [==============================] - 210s 783ms/step - loss: 0.7034 - val_loss: 0.6622\n",
            "Epoch 9/30\n",
            "268/268 [==============================] - 210s 783ms/step - loss: 0.5993 - val_loss: 0.5785\n",
            "Epoch 10/30\n",
            "268/268 [==============================] - 207s 775ms/step - loss: 0.5131 - val_loss: 0.5122\n",
            "Epoch 11/30\n",
            "268/268 [==============================] - 208s 777ms/step - loss: 0.4380 - val_loss: 0.4568\n",
            "Epoch 12/30\n",
            "268/268 [==============================] - 209s 780ms/step - loss: 0.3781 - val_loss: 0.4123\n",
            "Epoch 13/30\n",
            "268/268 [==============================] - 211s 786ms/step - loss: 0.3279 - val_loss: 0.3767\n",
            "Epoch 14/30\n",
            "268/268 [==============================] - 211s 785ms/step - loss: 0.2880 - val_loss: 0.3492\n",
            "Epoch 15/30\n",
            "268/268 [==============================] - 211s 786ms/step - loss: 0.2543 - val_loss: 0.3245\n",
            "Epoch 16/30\n",
            "268/268 [==============================] - 212s 789ms/step - loss: 0.2262 - val_loss: 0.3054\n",
            "Epoch 17/30\n",
            "268/268 [==============================] - 212s 791ms/step - loss: 0.2030 - val_loss: 0.2898\n",
            "Epoch 18/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 0.1842 - val_loss: 0.2758\n",
            "Epoch 19/30\n",
            "268/268 [==============================] - 213s 794ms/step - loss: 0.1668 - val_loss: 0.2656\n",
            "Epoch 20/30\n",
            "268/268 [==============================] - 212s 792ms/step - loss: 0.1519 - val_loss: 0.2563\n",
            "Epoch 21/30\n",
            "268/268 [==============================] - 210s 784ms/step - loss: 0.1390 - val_loss: 0.2483\n",
            "Epoch 22/30\n",
            "268/268 [==============================] - 213s 793ms/step - loss: 0.1277 - val_loss: 0.2423\n",
            "Epoch 23/30\n",
            "268/268 [==============================] - 212s 792ms/step - loss: 0.1179 - val_loss: 0.2364\n",
            "Epoch 24/30\n",
            "268/268 [==============================] - 215s 802ms/step - loss: 0.1078 - val_loss: 0.2327\n",
            "Epoch 25/30\n",
            "268/268 [==============================] - 213s 793ms/step - loss: 0.1007 - val_loss: 0.2292\n",
            "Epoch 26/30\n",
            "268/268 [==============================] - 214s 800ms/step - loss: 0.0938 - val_loss: 0.2248\n",
            "Epoch 27/30\n",
            "268/268 [==============================] - 214s 798ms/step - loss: 0.0877 - val_loss: 0.2236\n",
            "Epoch 28/30\n",
            "268/268 [==============================] - 213s 794ms/step - loss: 0.0816 - val_loss: 0.2216\n",
            "Epoch 29/30\n",
            "268/268 [==============================] - 214s 799ms/step - loss: 0.0766 - val_loss: 0.2191\n",
            "Epoch 30/30\n",
            "268/268 [==============================] - 213s 795ms/step - loss: 0.0722 - val_loss: 0.2171\n",
            "Model: \"encoder_decoder_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_4 (Encoder)          multiple                  1624818   \n",
            "_________________________________________________________________\n",
            "decoder_6 (Decoder)          multiple                  5216947   \n",
            "=================================================================\n",
            "Total params: 6,841,765\n",
            "Trainable params: 6,841,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "68678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.8371574954566796\n",
            "Italian\t devo andare a fare la spesa tornerò tra unora\n",
            "English_out\t i have to go shopping i will be back in an hour <end>\n",
            "Predicted\t i have to go shopping i am back to a couple <end>\n",
            "\n",
            "\n",
            "Italian\t hai dei fratelli\n",
            "English_out\t do you have any brothers <end>\n",
            "Predicted\t do you have any brothers <end>\n",
            "\n",
            "\n",
            "Italian\t hai corso alcuni rischi non necessari\n",
            "English_out\t you took some unnecessary risks <end>\n",
            "Predicted\t you took some unnecessary risks <end>\n",
            "\n",
            "\n",
            "Italian\t tom minacciò mary con la sua pistola\n",
            "English_out\t tom threatened mary with his gun <end>\n",
            "Predicted\t tom threatened mary with his hat <end>\n",
            "\n",
            "\n",
            "Italian\t io amo i panda\n",
            "English_out\t i love pandas <end>\n",
            "Predicted\t i love pandas <end>\n",
            "\n",
            "\n",
            "Italian\t tom divenne un tossicodipendente\n",
            "English_out\t tom became a drug addict <end>\n",
            "Predicted\t tom became a drug addict <end>\n",
            "\n",
            "\n",
            "Italian\t non darlo a tom\n",
            "English_out\t do not give it to tom <end>\n",
            "Predicted\t do not give tom that <end>\n",
            "\n",
            "\n",
            "Italian\t lei non piace a tom e mary\n",
            "English_out\t tom and mary do not like you <end>\n",
            "Predicted\t do not you and mary likes tom <end>\n",
            "\n",
            "\n",
            "Italian\t tom non sapeva neanche cosera quello\n",
            "English_out\t tom did not even know who that was <end>\n",
            "Predicted\t tom did not even know what this was <end>\n",
            "\n",
            "\n",
            "Italian\t tom pensava che avreste vinto\n",
            "English_out\t tom thought you would win <end>\n",
            "Predicted\t tom thought that you would win <end>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nWDeHAv4nDc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "outputId": "9ad696eb-6b71-4097-f171-3a7ba0d39dd4"
      },
      "source": [
        "norm = np.linalg.norm(np.array(att))\r\n",
        "normal_array = np.array(att)/norm\r\n",
        "attention_plot= np.array(normal_array)\r\n",
        "print(len(validation['italian'].iloc[i].split()))\r\n",
        "plot_attention(attention_plot, ans, validation['italian'].iloc[i])\r\n"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWMAAAFrCAYAAAAEkeiMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7xtc73/8dfHdsu1i0vRVSUi95McQu2k25HKryJFOpRUOt3vqZOUUEqSSlS66ebSzTllE6GEX0gJbbdd7oW92Rf7c/74jsU0zTnXWnPPueZ3ba/n47Eea84xx3eM79we3nvs7/h+PyMyE0nSaC0z6g5IkgxjSaqCYSxJFTCMJakChrEkVcAwlqQKGMaSVAHDWJIqYBhLUgUMY0mqgGE8JBGxfER8LCKuiIh7IuLe1p9R909SXQzj4flvYC/gcGAx8G7gi8CtwJtH2C9JFQoLBQ1HRPwN2D8zfxERdwKbZeZVEbE/MDMzdxtxFyVVxCvj4Vkb+FPz+i7g4c3rXwDPH0mPJFXLMB6ea4F1mtdXAjs3r7cB7h5JjyRVyzAenh8DM5vXRwIfa4Yujge+OowTRsQzIuKoiPh5RDym2bZrRGw+jPNJGhzHjKdIRGwNbAtckZmnDeH4zwdOAX4OvAjYMDOvjoh3As/OzF0HfU5Jg2MYD0lErJGZt0zh+c4HTsjMo5sbhps2YbwlcGpmrjPOISSNkMMUwzMnIk6LiFdFxIpTcL6NgZ912H4b8MgpOL+kJWAYD89LgFuAY4EbI+L4iJgZETGk890GrNth+xbA9UM6p6QBMYyHJDNPz8y9KVPc9gMeQblyvS4iPjOEU34b+ExEPBZIYNmI2AE4DPjGEM4naYAcM55CEbEhJTQ3ycwZAz72cpSZGq8GgrLqL5rz7Z2ZLsGWKmYYD1lErAy8DHgNZarbtcCJmfnRIZ1vPcrQxDLARZn512GcR9JgGcZDEhEvpgTwLpRFHt8HvpWZ5w7pfB8BDsvMeW3bHwa8OzM/PozzShoMw3hIImIecCrwLeDnmbloyOe7F3hMZt7Utv1RwE2DHhaRNFjLjroDS7G1M/POKTxfUG7ctducMtNCUsUM4yFpDeKIeDSwfNvn1w7iPM0Cj2x+ro6I1kCeAawIHDOIc0kaHocphiQiVgc+D7yStiAGGNSwQUTsRbkqPg54O/Cvlo8XALOHNU4taXC8Mh6ew4BNgV2BHwH7UBZlHAi8c1AnycwT4L76yecMe2xa0nB4ZTwkEXE9sHtm/iYi7gC2yMwrI2J3YJ/M3GnA53s6cG9m/qV5vxPlSSOXAYc6z1iqmyvwhufhwDXN638Bj2penwv8+xDOdxzlZh0R8TjgZEpNigOATwzhfJIGyDAenquA9ZrXlwOvbupSvJzhzG7YALiweb0bcH5mvgh4LbD7EM4naYAcMx6e44FNgFnAp4DTgLdQ/gI8cAjnm0G5YQdlpd9YBberKPUxempW7j2dMivj8sy8egh9lNSFY8ZTJCIeD2wF/DUzLxnC8c8FzqKE/unAMzPzkojYBvh+Zj6uS7vVgK8Br6DUs4AyO+OHwBumeK609JDlMMUUaeYVnzqMIG68F9iXciX+nZbz7AL8rke7IylX8M8BHtb8zGy2fW5IfZXUxivjIYmItwE3ZOYPm/dfo8xuuArYZWzWw4DPOQNYLTNvb9n2RGBe+zLpls9vBXbNzN+0bd8e+HFmPqpTO0mD5ZXx8LwNuBnuC7ZXAnsAFwOHD+OEzfS1GRGxdUSs0Gyb3S2IGw8Dbu2w/TbK6j1JU8AwHp51gb81r/8DOCkzvw8cBDxr0CeLiFUj4iTgJuC3zfmJiGMi4qAeTc8B/jsiVmo51srAx5rjSJoChvHw3AGs1bzeCfhV83ohw7ni/DSwDqWW8d0t20+j1FPu5h2UvxxuiIgzI+JM4Dpga8ryaklTwKltw3M68JWIuBB4CvDzZvtG3H/FPEi7AC/LzIvbigVdzv3znR+kmXHxVErt5Q2azd+kFMC/u1s7SYNlGE9ARKwNbEu50n3AvyYy8+guzQ4ADgYeD+yWmWMLPbYAvjOEbj6CzmO/qwJdl0I349m/zcyvtG1fNiK2z8yzBttNSZ04m2IcEbEn8FXK3NvbeWDN4MzMdUbSsTYRMQv4SWZ+rimruUlm/i0ivgQ8oVmN16mdRemlCnhlPL6DgUOBj/dTES0i1qHzFfWFnVvc124r4MnAaZk5t7mpNr9HHz4A/DIiNqL8d31H8/qZwPa9TkXnovSPAub26qOkwTGMx7cacPxkgzgiNqc8cmkDSuC1Ssry5U7t1qYU+Xlms99TgauBI4B76LKUOjN/26y2ezdlLvNMSq2KbTotNImIU1r68q2ImN/y8QxgY5xNIU0Zw3h8JwIvBr4wyXbHUmYl7AvMofPVZyefBW6kXJm2Pg3kpG59iIjlKMH/gczca4LnGRtfHht+ab1ZtwA4G/hKeyNJw+GY8TgiYnngJ5SAuoQyNe0+3Z66HBFzgc0z84pJnu9GYGZmXtqM/W6amVdHxJOASzNz5S7tbge2nGyBn4j4KOWp0g5JSCPklfH43gi8ALiFMkXtATfwgI5hTAnuRwOTCmPKirgFHbavSRmm6OZHlPKch03mZJn5scnsL2k4vDIeR0TcBBySmZ+dZLvnAp8EPkTnK+qONY0j4jTgj5n5gbFZEZThiu9TnuTxyi7tPgr8F3AmcAFtN98y84gu7R5JuUk5k843Glfr+UUlDYRhPI6mkM4zM/OqSbZb3PK29Q85KFPiut3AezolUC8GdqCsoNsIWB3Ytls/mmfgdZOZ2XHhR0T8mPKEkGPpMLY99ow9ScNlGI8jIg4D7ug2Ntyj3Q69Ps/MM3u0fTSwP7Al5Ur1QuCLmfn3yfRhIprn8+2UmecP+tiSJs4wHkdEHE2ptnYZ8EcePNzwtlH0q11E7EqZkzzZKXhXAi/NzMuG0zNJE2EYjyMizujxcWbmc3u0fQblBuCTKU+E/nsTmtdk5kU92q0EbEbnMdwfdWkzjzI97STgm5l5To9+t7Z7FaW8516ZeddE2kgaPMN4SCLi+cAplAJBLwI2bKaovRN4dmbu2qXd8yi1KzoVde811rwq5UGke1Ce2nEt8G3gW5n55x79vAR4ImWhxzU8+Mp/kx5fU9KAGMYTFBErcv/Utqsys9c0MyLifOCEzDy6bb7wlpTHL3WsaRERlwG/pyzgmNNnX9cBXk0J5s2BCzPz37rs+9Fex3LqmzQ1DONxNKvbPkl5svPylNkQ8ymr4T6YmQu7tJsLbJSZszss3rg8MzvWNG7abTLZ2RsdjrM8paj9h5rjWfBHqpjF5cf3aWBP4E3A+pRaEfsDrwUO6dHuNpqnbbTZAri+R7tzgKf11VMgIp4TEV+lLKn+KmUmxvP6PZ6kqeEKvPHtQbn59rOWbVdFxM2UsHtXl3bfBj4TEa+kDG0s20x3Owz4euuOEbFFy9tjgMOaoYZOi0U6VnuLiM9QhibWAn4B7AeckpnzO+x7B7BeZt7SXLV3/eeRiz6kqeEwxTgi4m5gs/anOUfEBsBFmfmwLu2WA46nBGQAiyn/EjkR2Lt5eOjYvospgdhe3a1drxt451CKBX2v2+q+ln33Ar6bmfOb171O6KIPaQoYxuOIiPOAP2TmAW3bv0QJ6W3Gab8esB0lbM/NzCs77POEifYnM6/pca5lKaU3H08Z325t940ubX5CeczSqZnZqSaGpClgGI+jeSzRz4AbgPOazc+iPPzzhZl5do+2b6c88HNs7HgOpS7x57LLH3xEHAxcl5nHtG1/E7BuZn64S7unAadSnncXlEctLUsZ5pjfbbghIr5NeX7eQuCHlDnKXVcHShoOb+CNbzblxt0PgFWan5MoN9mu7dYoIg4FDgK+THk69E6U8eCPUG4KdvNaoNOCkD8Ar+vR7kjKzbrVgXnAhsBWlBoXr+jWKDP3ANYG3kr5C+Z/IuKaiPhURGzc43ySBsgr43H0+4y4iLgN2C8zf9C2fTfgy5nZaVEHEXEP8PT2usTNcMefekyJuxXYoamD/C9KcaO/NDcNvzDRxRsRsSbwKsrskQ0y05u80hTwynh83Z4Rtwq96wtDqWXRaVuvP/drgWd32L49vafEBeWKGOBm7h8auZ6yWGVczcKW5wI7U/41cN1E2klacl71dBERn29eJnBIU/thzAzKjbKLexziG8ABPPiZdftTbph182Xgs82ijV8322ZS5jT3Gt64FNiU8ry83wHvba7q9wUedNNwTEQEZQjlNcCulLHmkyhPG/lNj/NJGiDDuLtnNL+DMv7aOtNgAWV8ttdTNVYA9oiInbn/xt/WlHHZE1vC/gGV3zLz8IhYA/g898+IWAAcmZmH9jjfwcDYI5k+BPwUOIPyhJKOBekbf6c8dPXnwN7AT51VIU09x4zHERFfBw7MzDsm2a5XtbdWHSu/RcTKwNObt5f3U1GteYrH7d1mbjT77AuclJn/nOzxJQ2OYSxJFfAGniRVwDCWpAoYxpMUEfvZzna2mz7tpkMfwTDuR19/0Lazne1G1m469NEwlqQaOJuig+VjhVzxvim7D7SQ+SzHCpM+pu1s91BqF8v0vs5bkPewfDx4ZX8+rHcfFi6cy3LLPfj/zYWrdj/fonlzWXalzv8/L16+e/7de9dcZqzSuV0s6l7t9t65c5mxcud28+dcf0tmrtnpMxd9dLAiK7N1zBx1N6Rpa5mHrdRXu8WbTGjl/oPcsOMqfbWb+/hFfbVb/rb+nmJ25Qff2bUErsMUklSB6sI4ImZFxFGj7ockTaXqwliSHoqqCuOIOB7YATggIrL5eWJEbB8R50fEPRFxY0SMVTUbazcrIr4UEYdHxG0RcXNEHBgRK0TEFyPinxFxbUS8dmRfTpJ6qCqMKeUmz6U8Pfkxzc9CSkWxi4DNgTcAu1NKSrZ6DXAnpTLap4DPAT8BrqA88eIE4KsR8ZihfwtJmqSqwjgz/0UpFzkvM/+Rmf8A3kx5dtybM/PyzDwNeB/wlohovWV7WWYelJl/pTxn7hZgYWYe2TwE9OOUcpjbdjp3ROwXERdExAULedDT7SVpqKoK4y42BM7LzMUt286m1PptnQdz31M1mpKRNwGXtGxbCNwOrNXpJJl5bGZulZlb9TPfUpKWxHQI415aZ2wv7PBZp23T/TtLWgrVGEwLKI81GnM58KyIaO3rds1+V01lxyRpWGoM49nAM5tZFGsAR1MeVXR0RGwYES+m3KA7KjPn9TiOJE0bNYbxYZSr3j9RnnK8HPBCykyKi4HjgO8AHxhVByVp0KqrTZGZVwDbtG2eTZmy1q3Njh22bdxh26OXsHuSNBTVhbGkwVtm1VX7ajd/6/X7anfzFv3NSIp7+2rG6lcvHn+nDtY5q79prMvefGdf7a7s8VmNwxSS9JDTVxhHxI7NUuU1Bt2hfjR92W3U/ZCkfk0ojKd7JbVmZkZGxFaj7oskdeIwhSRVYNww7lRJDXhi8/GmTTW1eU1dhy3a2r48Ii6JiPkRcV1EfDAiouXz2RHxrrY2D7gKj4i1I+KUiLg7Iq6JiNdHxKURcVBbVx8ZESdFxNyIuDoi9mz57G/N798332HWeN9bkqbSRK6MO1VSu6757BBK0Z4tgFuBE8fCNiK2BE4CfgQ8o9nv/cBbJtnHE4AnAM8FXgrs2bxv9xHgZGBT4HvAcRHx+OazZza/X9D0/+WT7IMkDdW4YdylktrYBJQPZ+YZmflnSlW0DYB1m8/eAZyZmR/NzCsy80TKgo73TrRzEfE0YGfgjZl5bmZeDOwNdHrA1jcz81tNhbYPA4uA7ZvPbm5+39p8h9s6nMuqbZJGZknHjP/Y8npO83usKtqGwDlt+58NrBsRq03w+BsAi4ELxjZk5nUt5+rYl8xcRAngjhXaOrFqm6RRWtIwbq2KNlZBbSLHHNt3MaXGcKvlBtCXsXN4g1LStDDRsGqvpDYRl/PgQu7bAddn5tjylZspY7gARMSKlKvhMX9u+rhlyz6PpRQOmowFze/+nq8tSUM20TCezQMrqU2k3eHADhFxUESsHxGvAd4JHNqyz6+B1zSLSDaiFAG6b4l2Zv4F+CVwTEQ8KyI2o9xInMcDaxmP5ybgbmDnZnbG6pNoK0lDN9Ewbq+k9vjeu0NmXgj8P+AVwKWUspefAloXjxxCCeSTgdMpY8oXtR1qb+B6YBZwCnAiJVzvmWDfx8aQ3wb8J2W8+eSJtpWkqRDlCUXTR3NlPgfYPTN/OIxzrBaPzK1j5jAOLY3E0l4oaNXr+isUtPL1d/fVrt9CQb+84tA/ZGbHlcDVV22LiOcCq1KeZ7cWcDDlYaO/GGW/pFFY9nGP7avdvOP6u11ywy2L+mr3pM8uGH+nDpa5tL+H9yy+u79Qpc+L0T7/zuip+jCmzK74BLAeZaz4PGD7zJw70l5J0gBVHcYRsSPlCnjNzLxlxN2RpKGpah7usKrDTfeqc5KWflWFsSQ9VFUTxv1Wh4uIR0XEdyLi+qay22UR8fpex42IseNKUhWqCWP6rA4HrAhcCLwE2Ag4EvhyxH1z03odV5KqUM0NvMz8V0TcVx0OICLGlkZ/ODPPaLZ9nKbgEGVp9Q3AZ1oOdWwzHW534FedjttJROwH7AewYseicJI0PDVdGffStTpcRMxoitb/MSJujYi7KPWKx10l2MqqbZJGqZor43H0qg73LkrNiwMpC0PuAj7JJMpnStKo1RbG/VSH2w44NTO/CdCMJa8P/HMJjytJU6a2YYrZTL463BXAzIjYrhljPgp4Uq/jRkRt31vSQ1xtoTTp6nCUpdK/A34OnAXMpVR2W9LjStKUqWqYIjOvALZp23x82z6zaXk6SGbezjgPGO1yXEmqRlVhLD1kRPvTxibmqn0f11e7dz/2x321+8bnd+mr3TKXXdZXu6muvlaT2oYpJOkhyTCWpAoYxpJUAcNYkipQZRhHxOuapc0rtG0/MSJOaV6/MSKujIgFze992/bNiNitbdvsiHjX8L+BJE1OlWEMnETp20vHNkTE6sDLgK9FxMsoizs+B2xMqdR2dET8xwj6KklLrMqpbZl5d0ScCOwDfL/ZvAdwB/BT4Ezgm5k59vSOKyJiS+C9wKn9nNOqbZJGqdYrY4CvADtFxNjjcPcBTsjMRcCGwDlt+58NPL3fk1m1TdIoVRvGmfn/KUXj946IjYGtgOPGa9b2un1m/XKD66EkDU61Ydz4CrA38J/AOZn5l2b75cC2bftuR6k9MeZmylM9AIiItVvfS1JNqhwzbvEd4Ahgf+BNLds/A5wUEX8ATgdeALyGB9ao+DXluXe/Be6l1Di+Zyo6LUmTVfWVcWbeSbmBN5/7b+SRmT8B3gr8F+Vq+EDgzZnZevPuncDVwCzgB8BXgZumpOOSNEm1XxlDGVr4XmbObd2YmccAx3RrlJlzgBe2bf7h4LsnSUuu2jCOiEcAzwaeD2w64u5IA7XsE/qrvvbD1x3RV7tdv/uOvtqtf+E1fbVbdHefI4JLQfW1flUbxsBFwCOBD2TmpaPujCQNU7VhnJlPnMz+EXE8sEZmvqTHPqcBt2Tm3kvUOUkasKpv4EnSQ4VhLEkVGEoYR8QLIuLOiFi2ef+UporaMS37fCIi/rd5vX1EnB8R90TEjRHx2YhYvmXfWRFxVNs5jm+GHbr1YaVmn7uaY35g8N9UkgZjWFfGZwMrUpYwA+wI3NL8pmXbrIhYl/Jk54uAzYE3ALsDhyxhHw4DdgJeAcxsjr39Eh5TkoZiKGGcmXcBfwCe02zakVLy8gkR8ZiIWAn4N8qCjDcDcyiLNi7PzNOA9wFvafabtIhYhRLq78nMXzazMV4PLO7RZr+IuCAiLljI/H5OK0l9G+aY8SzuvxLegXL1e36z7d+BRcDvKBXYzsvM1qA8G1geeEqf535y0/7csQ3NXxCXdGtg1TZJozTsMN42IjYEVqNcKc+iXC3vCJybmQvGOcbYDPDFWIFN0lJsmGF8NrAC8B7g7My8lweG8axmv8uBZ0VEa1+2AxYAVzXvH1CBrdFrVd5VwELgWWMbImJlylNBJKk6QwvjlnHjPYEzms3nAY+lhOSsZtvRwDqUxyZtGBEvBj4FHJWZ85p9fg28MCJ2iYinRcQRQNf1pM25vwZ8OiJ2ioiNKLWQZwzyO0rSoAx7Bd4sYOvmN5l5T0ScT7l597tm2w0R8UJKWcyLgX8C3wZap6IdB2zC/cXlvwj8GFijx7nfBazc7DcP+ELzXpKqM9Qwzsz3UWZGtG7bscN+Z1FCu9txFgIHND/d9tm77f1c4HXNjyRVrdraFNLSLPusavalm3fsq92M9e7qq12u0t/DeWOZ9vvtEzxf18mnSz+XQ0tSBZaaMI6IJzZLrrcaf29JqsvSNExxHWX62y2j7ogkTdZSE8bNPOZ/jLofktSPqocpJlP9rX2YIiJ2bN7PbCrCzWtqT2wxqu8jSd1UHcZMovpbj2McQpletwVwK3BiRPR3q1eShqTqMJ5k9bduPpyZZ2Tmn4GPAxsA67bvZNU2SaNUdRg3ZjGx6m/d/LHl9Zzm91rtO1m1TdIoTZcwXpLqbwtbXo9VgZsO31vSQ8h0CKWJVn+TpGmr+jCeRPU3SZq2qg/jxizKnOhZUKq/UcaN59N7vFiSpoVpsehjItXfMnM2LU8DycxZtD0dpH0fSarFtAhjaWmzYMPH9tXuqHVP76vd5l/fsq92ef3V/bVbtKivdg9l02WYQpKWatM6jCPiXRExe9T9kKQlNa3DWJKWFkML44hYLSIePqzjdznnmhGx4lSeU5IGYaBhHBEzImLniPg2pZzlps321SPi2Ii4qanCdmZrEfiI2Dsi7moqrF0aEXMj4oyIeFLb8d8TEf9o9v0GsEpbF14E/KM517aD/G6SNEwDCeOI2CgiDqUUeP8eMBd4AXBWUyHtp5TiPC8BNgfOAn4dEY9pOcwKwPuBfYBtgIcDraUyXwl8AvgopQLbX4B3tHXlRGAPYFXgfyLiyoj4SHuoS1Jt+g7jiHhURLwtIv4AXESphnYg8OjM3Dczz8rMpCxb3gzYLTN/l5lXZuaHgauB17YcclnggGafPwKHATu2lLt8O3BCZn45M6/IzINpW/CRmYsy82eZuTvwaOCTzfn/GhGzImKfiGi/mh77PlZtkzQyS3Jl/FbgSOAeYP3M3CUzT2pWx7XaElgJuLkZXrgrIu4CNgae3LLf/Mz8S8v7OcDywCOa9xsC57Ydu/39fTLzjsw8LjOfQymzuTbwNWC3LvtbtU3SyCzJoo9jKRXRXgdcGhE/Br4J/Kop5jNmGeBG4NkdjnFHy+v2WeJLVGEtIlagDIvsSRlLvoxydX1yP8eTpGHq+8o4M+dk5sGZ+TTgecBdwHeB6yPi8IjYrNn1QspV6eJmiKL156ZJnPJySmGgVg94H8V2EfFlyg3ELwBXAltm5haZeWRm3j75bytJwzWQG3iZeV5m7k95OvNbgfWB30fEs4H/Bc4BTo6IF0bEkyJim4j4WPP5RB0J7BUR+0bEUyPi/cDWbfvsCZxOqXu8O/C4zHx3Zl66hF9RkoZqoLUpMnM+8APgBxGxFnBvZmZEvIgyE+IrlKds3EgJ6G9M4tjfi4j1gIMpY9CnAEcAe7fs9ivKDcQ7HnwESarX0AoFtQ5BZOadlJkWB3bZ93jg+LZts3hw1bVDKA8YbXVQy+dzkKRpyKpt0gjMmHVhX+12Xmez8XfqYC1+21e7xX21Uj+sTSFJFTCMJakChrEkVcAwlqQKGMaSVAHDWJIq4NS2RkTsB+wHsCIrjbg3kh5qvDJuWLVN0igZxpJUAcNYkipgGEtSBQxjSaqAYSxJFTCMJakChrEkVcAwlqQKGMaSVAHDWJIqYBhLUgUMY0mqgFXbGlZtkzRKXhk3rNomaZQMY0mqgGEsSRUwjCWpAoaxJFXAMJakChjGklQBw1iSKmAYS1IFDGNJqoBhLEkVMIwlqQKGsSRVwKptDau2SRolr4wbVm2TNEqGsSRVwDCWpAoYxpJUAcNYkipgGEtSBQxjSaqAYSxJFTCMJakChrEkVcAwlqQKGMaSVAHDWJIqYNW2hlXbJI2SV8YNq7ZJGiXDWJIqYBhLUgUMY0mqgGEsSRUwjCWpAoaxJFXAMJakChjGklQBw1iSKmAYS1IFDGNJqoBhLEkVsGpbw6ptkkbJK+OGVdskjZJhLEkVMIwlqQKGsSRVwDCWpAoYxpJUAcNYkipgGEtSBQxjSaqAYSxJFTCMJakChrEkVcAwlqQKWLWtYdU2SaPklXHDqm2SRskwlqQKGMaSVAHDWJIqYBhLUgUMY0mqgGEsSRUwjCWpAoaxJFXAMJakChjGklQBw1iSKmAYS1IFrNrWsGqbpFHyyrhh1TZJo2QYS1IFDGNJqoBhLEkVMIwlqQKGsSRVwDCWpAoYxpJUAcNYkipgGEtSBQxjSaqAYSxJFTCMJakCVm1rWLVN0ih5ZdywapukUTKMJakChrEkVcAwlqQKGMaSVAHDWJIqYBhLUgUMY0mqgGEsSRUwjCWpAoaxJFXAMJakChjGklQBq7Y1rNomaZS8Mm5YtU3SKBnGklQBw1iSKmAYS1IFDGNJqoBhLEkVMIwlqQKGsSRVwDCWpAoYxpJUAcNYkipgGEtSBSwU1LBQkKRR8sq4YaEgSaNkGEtSBQxjSaqAYSxJFTCMJakChrEkVcAwlqQKGMaSVAHDWJIqYBhLUgUMY0mqgGEsSRUwjCWpAlZta1i1TdIoeWXcsGqbpFEyjCWpAoaxJFXAMJakChjGklQBw1iSKmAYS1IFDGNJqoBhLEkVMIwlqQKGsSRVwDCWpAoYxpJUAau2NazaJmmUvDJuWLVN0igZxpJUAcNYkipgGEtSBQxjSaqAYSxJFTCMJakChrEkVcAwlqQKGMaSVAHDWJIqYBhLUgUMY0mqgFXbGlZtkzRKXhk3rNomaZQMY0mqgGEsSRUwjCWpAoaxJFXAMJakCkRmjroP1YmIm4Fruny8BnBLH4e1ne1sN5p2NfXxCZm5ZsdPMtOfSfwAF9jOdrabPu2mQx8z02EKSaqBYSxJFTCMJ+9Y29nOdtOq3XToo3dG0XQAAAAjSURBVDfwJKkGXhlLUgUMY0mqgGEsSRUwjCWpAoaxJFXg/wCrS33NWR6CJQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 360x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VB1jRUqZQ9AM"
      },
      "source": [
        "<font color='blue'>**Repeat the same steps for Concat scoring function**</font>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1kN9ZWViQNMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5edbdf8-6b02-44f2-b863-2dbf178a2aee"
      },
      "source": [
        "#Compile and train your model on concat scoring function.\n",
        "# Visualize few sentences randomly in Test data\n",
        "# Predict on 1000 random sentences on test data and calculate the average BLEU score of these sentences.\n",
        "# https://www.nltk.org/_modules/nltk/translate/bleu_score.html\n",
        "model  = encoder_decoder(encoder_inputs_length=20,decoder_inputs_length=20,output_vocab_size=vocab_size_eng,score_fun='concat',att_units=16)\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "model.compile(optimizer=optimizer,loss=custom_lossfunction)\n",
        "logdir = \"logs/fit/\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)\n",
        "batch_size=1024\n",
        "train_steps=train.shape[0]//1024\n",
        "valid_steps=validation.shape[0]//1024\n",
        "model.fit_generator(train_dataloader, steps_per_epoch=train_steps, epochs=30, validation_data= test_dataloader, validation_steps=valid_steps,callbacks=tensorboard_callback)\n",
        "model.summary()\n",
        "def predict(input_sentence):\n",
        "\n",
        "  '''\n",
        "  A. Given input sentence, convert the sentence into integers using tokenizer used earlier\n",
        "  B. Pass the input_sequence to encoder. we get encoder_outputs, last time step hidden and cell state\n",
        "  C. Initialize index of <start> as input to decoder. and encoder final states as input_states to onestepdecoder.\n",
        "  D. till we reach max_length of decoder or till the model predicted word <end>:\n",
        "         predictions, input_states, attention_weights = model.layers[1].onestepdecoder(input_to_decoder, encoder_output, input_states)\n",
        "         Save the attention weights\n",
        "         And get the word using the tokenizer(word index) and then store it in a string.\n",
        "  E. Call plot_attention(#params)\n",
        "  F. Return the predicted sentence\n",
        "  '''\n",
        "  encoded              = tknizer_ita.texts_to_sequences([input_sentence])\n",
        "  encoded              = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(encoded, maxlen=20, dtype='int',padding='post'))\n",
        "  initial_state        = model.layers[0].initialize_states(batch_size=1)\n",
        "  encoder_outputs, h , c = model.layers[0](encoded,initial_state)\n",
        "  start                = tknizer_eng.word_index['<start>']\n",
        "  output_sentence=[]\n",
        "  attention_weights_list=[]\n",
        "  attention_plot=np.zeros((20,20))\n",
        "  for i in range(20):\n",
        "   decoder_output = model.layers[1](tf.expand_dims([start],axis=1),encoder_outputs,h,c)\n",
        "   output_dense,h,c,attention_weights,context_vector = model.layers[1].layers[0](tf.expand_dims([start],axis=1),encoder_outputs,h,c)\n",
        "   word_index=(tf.math.argmax(decoder_output[0][0]))\n",
        "   attention_weights = tf.reshape(attention_weights, (1,20))\n",
        "   attention_plot[i]=(attention_weights.numpy()[0])\n",
        "   english_word=tknizer_eng.index_word[word_index.numpy()]\n",
        "   start=word_index.numpy()\n",
        "   output_sentence.append(english_word)\n",
        "   if english_word=='<end>':\n",
        "     break\n",
        "  return \" \".join(output_sentence),attention_plot"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/data/ops/dataset_ops.py:3504: UserWarning: Even though the tf.config.experimental_run_functions_eagerly option is set, this option does not apply to tf.data functions. tf.data functions are still traced and executed as graphs.\n",
            "  \"Even though the tf.config.experimental_run_functions_eagerly \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "268/268 [==============================] - 212s 791ms/step - loss: 2.0702 - val_loss: 1.6613\n",
            "Epoch 2/30\n",
            "268/268 [==============================] - 212s 790ms/step - loss: 1.6319 - val_loss: 1.5096\n",
            "Epoch 3/30\n",
            "268/268 [==============================] - 211s 788ms/step - loss: 1.4614 - val_loss: 1.3047\n",
            "Epoch 4/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 1.2641 - val_loss: 1.1514\n",
            "Epoch 5/30\n",
            "268/268 [==============================] - 212s 792ms/step - loss: 1.1102 - val_loss: 1.0231\n",
            "Epoch 6/30\n",
            "268/268 [==============================] - 211s 787ms/step - loss: 0.9781 - val_loss: 0.9016\n",
            "Epoch 7/30\n",
            "268/268 [==============================] - 211s 786ms/step - loss: 0.8528 - val_loss: 0.7974\n",
            "Epoch 8/30\n",
            "268/268 [==============================] - 212s 790ms/step - loss: 0.7440 - val_loss: 0.7054\n",
            "Epoch 9/30\n",
            "268/268 [==============================] - 212s 792ms/step - loss: 0.6489 - val_loss: 0.6286\n",
            "Epoch 10/30\n",
            "268/268 [==============================] - 211s 789ms/step - loss: 0.5663 - val_loss: 0.5593\n",
            "Epoch 11/30\n",
            "268/268 [==============================] - 211s 788ms/step - loss: 0.4912 - val_loss: 0.5023\n",
            "Epoch 12/30\n",
            "268/268 [==============================] - 214s 797ms/step - loss: 0.4270 - val_loss: 0.4523\n",
            "Epoch 13/30\n",
            "268/268 [==============================] - 211s 789ms/step - loss: 0.3726 - val_loss: 0.4100\n",
            "Epoch 14/30\n",
            "268/268 [==============================] - 212s 790ms/step - loss: 0.3280 - val_loss: 0.3802\n",
            "Epoch 15/30\n",
            "268/268 [==============================] - 210s 784ms/step - loss: 0.2912 - val_loss: 0.3524\n",
            "Epoch 16/30\n",
            "268/268 [==============================] - 212s 792ms/step - loss: 0.2596 - val_loss: 0.3298\n",
            "Epoch 17/30\n",
            "268/268 [==============================] - 211s 786ms/step - loss: 0.2324 - val_loss: 0.3111\n",
            "Epoch 18/30\n",
            "268/268 [==============================] - 211s 786ms/step - loss: 0.2097 - val_loss: 0.2963\n",
            "Epoch 19/30\n",
            "268/268 [==============================] - 212s 790ms/step - loss: 0.1907 - val_loss: 0.2843\n",
            "Epoch 20/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 0.1735 - val_loss: 0.2734\n",
            "Epoch 21/30\n",
            "268/268 [==============================] - 210s 782ms/step - loss: 0.1592 - val_loss: 0.2643\n",
            "Epoch 22/30\n",
            "268/268 [==============================] - 211s 788ms/step - loss: 0.1461 - val_loss: 0.2558\n",
            "Epoch 23/30\n",
            "268/268 [==============================] - 210s 783ms/step - loss: 0.1357 - val_loss: 0.2508\n",
            "Epoch 24/30\n",
            "268/268 [==============================] - 209s 780ms/step - loss: 0.1257 - val_loss: 0.2436\n",
            "Epoch 25/30\n",
            "268/268 [==============================] - 210s 785ms/step - loss: 0.1173 - val_loss: 0.2389\n",
            "Epoch 26/30\n",
            "268/268 [==============================] - 210s 785ms/step - loss: 0.1089 - val_loss: 0.2345\n",
            "Epoch 27/30\n",
            "268/268 [==============================] - 210s 785ms/step - loss: 0.1016 - val_loss: 0.2309\n",
            "Epoch 28/30\n",
            "268/268 [==============================] - 211s 789ms/step - loss: 0.0954 - val_loss: 0.2302\n",
            "Epoch 29/30\n",
            "268/268 [==============================] - 211s 788ms/step - loss: 0.0889 - val_loss: 0.2272\n",
            "Epoch 30/30\n",
            "268/268 [==============================] - 210s 784ms/step - loss: 0.0835 - val_loss: 0.2239\n",
            "Model: \"encoder_decoder_2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "encoder_5 (Encoder)          multiple                  1624818   \n",
            "_________________________________________________________________\n",
            "decoder_7 (Decoder)          multiple                  5216947   \n",
            "=================================================================\n",
            "Total params: 6,841,765\n",
            "Trainable params: 6,841,765\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5BIPM1I5zvP",
        "outputId": "3dc353b1-4e05-4319-deda-3e68578e1eda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Bleu=[]\r\n",
        "print(len(validation['italian']))\r\n",
        "for i in np.random.choice(np.arange(len(validation['italian'])),size=1000,replace=False):\r\n",
        "  ans,att=predict(validation['italian'].iloc[i])\r\n",
        "  Bleu.append(nltk.translate.bleu_score.sentence_bleu(validation['english_out'].iloc[i],ans))\r\n",
        "print(sum(Bleu)/1000)\r\n",
        "\r\n",
        "for i in np.random.choice(np.arange(len(validation['italian'])),size=10,replace=False):\r\n",
        "  ans,att=predict(validation['italian'].iloc[i])\r\n",
        "  print('Italian\\t',validation['italian'].iloc[i])\r\n",
        "  print('English_out\\t',validation['english_out'].iloc[i])\r\n",
        "  print('Predicted\\t',ans)\r\n",
        "  print('\\n')"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "68678\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n",
            "Corpus/Sentence contains 0 counts of 2-gram overlaps.\n",
            "BLEU scores might be undesirable; use SmoothingFunction().\n",
            "  warnings.warn(_msg)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "0.835481795830919\n",
            "Italian\t ha perseguito la sua carriera a spese della sua famiglia\n",
            "English_out\t he pursued his career at the expense of his family <end>\n",
            "Predicted\t he pursued his career at the expense of his family <end>\n",
            "\n",
            "\n",
            "Italian\t pianse\n",
            "English_out\t she cried <end>\n",
            "Predicted\t he cried <end>\n",
            "\n",
            "\n",
            "Italian\t io non voglio più combattere\n",
            "English_out\t i do not want to fight anymore <end>\n",
            "Predicted\t i do not want to fight anymore <end>\n",
            "\n",
            "\n",
            "Italian\t devi rispondere alla lettera\n",
            "English_out\t you have to reply to the letter <end>\n",
            "Predicted\t you have to reply to the letter <end>\n",
            "\n",
            "\n",
            "Italian\t sembrava un dottore\n",
            "English_out\t did he look like a doctor <end>\n",
            "Predicted\t he looked like a doctor <end>\n",
            "\n",
            "\n",
            "Italian\t sarà ancora qui questo pomeriggio\n",
            "English_out\t will you still be here this afternoon <end>\n",
            "Predicted\t are you going to be here this afternoon <end>\n",
            "\n",
            "\n",
            "Italian\t non sapeva che mary era la cugina di tom\n",
            "English_out\t did not you know mary was tom is cousin <end>\n",
            "Predicted\t did not you know mary was your girlfriend <end>\n",
            "\n",
            "\n",
            "Italian\t lei ha mai cantato in francese\n",
            "English_out\t have you ever sung in french <end>\n",
            "Predicted\t did you ever speak french <end>\n",
            "\n",
            "\n",
            "Italian\t non la sto lasciando indietro\n",
            "English_out\t i am not leaving you behind <end>\n",
            "Predicted\t i am not leaving you behind <end>\n",
            "\n",
            "\n",
            "Italian\t ho firmato il contratto di locazione di oggi\n",
            "English_out\t i signed the lease today <end>\n",
            "Predicted\t i signed the lease today <end>\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3FweDVX2MWdT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "outputId": "17b92a5d-0f46-48e8-bfe4-5dd211c19e83"
      },
      "source": [
        "norm = np.linalg.norm(np.array(att))\r\n",
        "normal_array = np.array(att)/norm\r\n",
        "attention_plot= np.array(normal_array)\r\n",
        "print(len(validation['italian'].iloc[i].split()))\r\n",
        "plot_attention(attention_plot, ans, validation['italian'].iloc[i])"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DU7k5jyNAeS6"
      },
      "source": [
        "tensorboard --logdir=./"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff1lV0ITM6_p"
      },
      "source": [
        "# Write your observations on each of the scoring function"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lW0MS0__8a2w"
      },
      "source": [
        "from prettytable import PrettyTable"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BMOsIiaP8a41",
        "outputId": "f38036d4-a362-484b-8f8f-f66d1fe522d9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "t = PrettyTable(['Function','Bleu score'])\r\n",
        "t.add_row(['Encoder_Decoder',0.834200935079292])\r\n",
        "t.add_row(['Attention_Dot', 0.8390026045640984])\r\n",
        "t.add_row(['Attention_General',0.8371574954566796])\r\n",
        "t.add_row(['Attention_Concat',0.835481795830919 ])\r\n",
        "print(t)"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+-------------------+--------------------+\n",
            "|      Function     |     Bleu score     |\n",
            "+-------------------+--------------------+\n",
            "|  Encoder_Decoder  | 0.834200935079292  |\n",
            "|   Attention_Dot   | 0.8390026045640984 |\n",
            "| Attention_General | 0.8371574954566796 |\n",
            "|  Attention_Concat | 0.835481795830919  |\n",
            "+-------------------+--------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}